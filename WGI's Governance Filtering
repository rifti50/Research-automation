{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaab7fd3",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-23T16:16:10.249595Z",
     "iopub.status.busy": "2025-05-23T16:16:10.248526Z",
     "iopub.status.idle": "2025-05-23T16:16:12.252650Z",
     "shell.execute_reply": "2025-05-23T16:16:12.251392Z"
    },
    "papermill": {
     "duration": 2.012122,
     "end_time": "2025-05-23T16:16:12.254530",
     "exception": false,
     "start_time": "2025-05-23T16:16:10.242408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/wgis-governance-1996-2023/Governance wgidataset with variable names.xlsx\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95e2d1d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T16:16:12.266320Z",
     "iopub.status.busy": "2025-05-23T16:16:12.265773Z",
     "iopub.status.idle": "2025-05-23T16:16:16.339526Z",
     "shell.execute_reply": "2025-05-23T16:16:16.338559Z"
    },
    "papermill": {
     "duration": 4.081117,
     "end_time": "2025-05-23T16:16:16.341118",
     "exception": false,
     "start_time": "2025-05-23T16:16:12.260001",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>countryname</th>\n",
       "      <th>year</th>\n",
       "      <th>indicator</th>\n",
       "      <th>estimate</th>\n",
       "      <th>stddev</th>\n",
       "      <th>nsource</th>\n",
       "      <th>pctrank</th>\n",
       "      <th>pctranklower</th>\n",
       "      <th>pctrankupper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1996</td>\n",
       "      <td>cc</td>\n",
       "      <td>-1.291705</td>\n",
       "      <td>0.340507</td>\n",
       "      <td>2</td>\n",
       "      <td>4.301075</td>\n",
       "      <td>0</td>\n",
       "      <td>27.419355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1996</td>\n",
       "      <td>cc</td>\n",
       "      <td>-0.893903</td>\n",
       "      <td>0.315914</td>\n",
       "      <td>3</td>\n",
       "      <td>19.354839</td>\n",
       "      <td>2.688172</td>\n",
       "      <td>43.010754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>1996</td>\n",
       "      <td>cc</td>\n",
       "      <td>-0.566741</td>\n",
       "      <td>0.262077</td>\n",
       "      <td>4</td>\n",
       "      <td>33.333332</td>\n",
       "      <td>16.666666</td>\n",
       "      <td>52.688171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>American Samoa</td>\n",
       "      <td>1996</td>\n",
       "      <td>cc</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "      <td>..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>1996</td>\n",
       "      <td>cc</td>\n",
       "      <td>1.318143</td>\n",
       "      <td>0.480889</td>\n",
       "      <td>1</td>\n",
       "      <td>87.096771</td>\n",
       "      <td>72.043015</td>\n",
       "      <td>96.774193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      countryname  year indicator  estimate    stddev nsource    pctrank  \\\n",
       "0     Afghanistan  1996        cc -1.291705  0.340507       2   4.301075   \n",
       "1         Albania  1996        cc -0.893903  0.315914       3  19.354839   \n",
       "2         Algeria  1996        cc -0.566741  0.262077       4  33.333332   \n",
       "3  American Samoa  1996        cc        ..        ..      ..         ..   \n",
       "4         Andorra  1996        cc  1.318143  0.480889       1  87.096771   \n",
       "\n",
       "  pctranklower pctrankupper  \n",
       "0            0    27.419355  \n",
       "1     2.688172    43.010754  \n",
       "2    16.666666    52.688171  \n",
       "3           ..           ..  \n",
       "4    72.043015    96.774193  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_file = '/kaggle/input/wgis-governance-1996-2023/Governance wgidataset with variable names.xlsx'\n",
    "df = pd.read_excel(input_file)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da508e18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T16:16:16.351330Z",
     "iopub.status.busy": "2025-05-23T16:16:16.350894Z",
     "iopub.status.idle": "2025-05-23T16:16:16.458779Z",
     "shell.execute_reply": "2025-05-23T16:16:16.457748Z"
    },
    "papermill": {
     "duration": 0.114827,
     "end_time": "2025-05-23T16:16:16.460522",
     "exception": false,
     "start_time": "2025-05-23T16:16:16.345695",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1996, 1998, 2000, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009,\n",
       "       2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020,\n",
       "       2021, 2022, 2023])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['year'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bc017c",
   "metadata": {
    "papermill": {
     "duration": 0.004115,
     "end_time": "2025-05-23T16:16:16.469621",
     "exception": false,
     "start_time": "2025-05-23T16:16:16.465506",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Filtering 52 Countries from 1998-2018 (all indicators are mixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d809fb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T16:16:16.480045Z",
     "iopub.status.busy": "2025-05-23T16:16:16.479712Z",
     "iopub.status.idle": "2025-05-23T16:16:20.234922Z",
     "shell.execute_reply": "2025-05-23T16:16:20.233856Z"
    },
    "papermill": {
     "duration": 3.762331,
     "end_time": "2025-05-23T16:16:20.236434",
     "exception": false,
     "start_time": "2025-05-23T16:16:16.474103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the governance dataset...\n",
      "Successfully read data with shape: (32100, 9)\n",
      "\n",
      "Dataset columns: ['countryname', 'year', 'indicator', 'estimate', 'stddev', 'nsource', 'pctrank', 'pctranklower', 'pctrankupper']\n",
      "Dataset shape: (32100, 9)\n",
      "\n",
      "First few rows:\n",
      "      countryname  year indicator  estimate    stddev nsource    pctrank  \\\n",
      "0     Afghanistan  1996        cc -1.291705  0.340507       2   4.301075   \n",
      "1         Albania  1996        cc -0.893903  0.315914       3  19.354839   \n",
      "2         Algeria  1996        cc -0.566741  0.262077       4  33.333332   \n",
      "3  American Samoa  1996        cc        ..        ..      ..         ..   \n",
      "4         Andorra  1996        cc  1.318143  0.480889       1  87.096771   \n",
      "\n",
      "  pctranklower pctrankupper  \n",
      "0            0    27.419355  \n",
      "1     2.688172    43.010754  \n",
      "2    16.666666    52.688171  \n",
      "3           ..           ..  \n",
      "4    72.043015    96.774193  \n",
      "\n",
      "Target countries (52): ['Argentina', 'Australia', 'Austria', 'Belgium', 'Brazil', 'Bulgaria', 'Canada', 'Chile', 'China', 'Colombia', 'Costa Rica', 'Croatia', 'Cyprus', 'Czech Republic', 'Denmark', 'Estonia', 'Finland', 'France', 'Germany', 'Greece', 'Hungary', 'Iceland', 'India', 'Indonesia', 'Ireland', 'Israel', 'Italy', 'Japan', 'Korea, Rep.', 'Latvia', 'Lithuania', 'Luxembourg', 'Malta', 'Mexico', 'Netherlands', 'New Zealand', 'Norway', 'Peru', 'Poland', 'Portugal', 'Romania', 'Russian Federation', 'Saudi Arabia', 'Slovak Republic', 'Slovenia', 'South Africa', 'Spain', 'Sweden', 'Switzerland', 'Türkiye', 'United Kingdom', 'United States']\n",
      "Target years: 1998 to 2018\n",
      "\n",
      "Identified columns:\n",
      "Country column: countryname\n",
      "Year column: year\n",
      "Indicator column: indicator\n",
      "Estimate column: estimate\n",
      "\n",
      "Filtering data...\n",
      "Unique countries in dataset: 214\n",
      "Sample countries: ['Afghanistan', 'Albania', 'Algeria', 'American Samoa', 'Andorra', 'Angola', 'Anguilla', 'Antigua and Barbuda', 'Argentina', 'Armenia']\n",
      "Year range in dataset: 1996 to 2023\n",
      "Data after country and year filtering: (5928, 9)\n",
      "\n",
      "Final filtered dataset:\n",
      "Shape: (5928, 4)\n",
      "Countries found: 52\n",
      "Years covered: 1998 to 2018\n",
      "Indicators: 6\n",
      "\n",
      "Summary by country:\n",
      "                    Min_Year  Max_Year  Years_Count  Indicators_Count  \\\n",
      "country                                                                 \n",
      "Argentina               1998      2018           19                 6   \n",
      "Australia               1998      2018           19                 6   \n",
      "Austria                 1998      2018           19                 6   \n",
      "Belgium                 1998      2018           19                 6   \n",
      "Brazil                  1998      2018           19                 6   \n",
      "Bulgaria                1998      2018           19                 6   \n",
      "Canada                  1998      2018           19                 6   \n",
      "Chile                   1998      2018           19                 6   \n",
      "China                   1998      2018           19                 6   \n",
      "Colombia                1998      2018           19                 6   \n",
      "Costa Rica              1998      2018           19                 6   \n",
      "Croatia                 1998      2018           19                 6   \n",
      "Cyprus                  1998      2018           19                 6   \n",
      "Czech Republic          1998      2018           19                 6   \n",
      "Denmark                 1998      2018           19                 6   \n",
      "Estonia                 1998      2018           19                 6   \n",
      "Finland                 1998      2018           19                 6   \n",
      "France                  1998      2018           19                 6   \n",
      "Germany                 1998      2018           19                 6   \n",
      "Greece                  1998      2018           19                 6   \n",
      "Hungary                 1998      2018           19                 6   \n",
      "Iceland                 1998      2018           19                 6   \n",
      "India                   1998      2018           19                 6   \n",
      "Indonesia               1998      2018           19                 6   \n",
      "Ireland                 1998      2018           19                 6   \n",
      "Israel                  1998      2018           19                 6   \n",
      "Italy                   1998      2018           19                 6   \n",
      "Japan                   1998      2018           19                 6   \n",
      "Korea, Rep.             1998      2018           19                 6   \n",
      "Latvia                  1998      2018           19                 6   \n",
      "Lithuania               1998      2018           19                 6   \n",
      "Luxembourg              1998      2018           19                 6   \n",
      "Malta                   1998      2018           19                 6   \n",
      "Mexico                  1998      2018           19                 6   \n",
      "Netherlands             1998      2018           19                 6   \n",
      "New Zealand             1998      2018           19                 6   \n",
      "Norway                  1998      2018           19                 6   \n",
      "Peru                    1998      2018           19                 6   \n",
      "Poland                  1998      2018           19                 6   \n",
      "Portugal                1998      2018           19                 6   \n",
      "Romania                 1998      2018           19                 6   \n",
      "Russian Federation      1998      2018           19                 6   \n",
      "Saudi Arabia            1998      2018           19                 6   \n",
      "Slovak Republic         1998      2018           19                 6   \n",
      "Slovenia                1998      2018           19                 6   \n",
      "South Africa            1998      2018           19                 6   \n",
      "Spain                   1998      2018           19                 6   \n",
      "Sweden                  1998      2018           19                 6   \n",
      "Switzerland             1998      2018           19                 6   \n",
      "Türkiye                 1998      2018           19                 6   \n",
      "United Kingdom          1998      2018           19                 6   \n",
      "United States           1998      2018           19                 6   \n",
      "\n",
      "                    Total_Observations  \n",
      "country                                 \n",
      "Argentina                          114  \n",
      "Australia                          114  \n",
      "Austria                            114  \n",
      "Belgium                            114  \n",
      "Brazil                             114  \n",
      "Bulgaria                           114  \n",
      "Canada                             114  \n",
      "Chile                              114  \n",
      "China                              114  \n",
      "Colombia                           114  \n",
      "Costa Rica                         114  \n",
      "Croatia                            114  \n",
      "Cyprus                             114  \n",
      "Czech Republic                     114  \n",
      "Denmark                            114  \n",
      "Estonia                            114  \n",
      "Finland                            114  \n",
      "France                             114  \n",
      "Germany                            114  \n",
      "Greece                             114  \n",
      "Hungary                            114  \n",
      "Iceland                            114  \n",
      "India                              114  \n",
      "Indonesia                          114  \n",
      "Ireland                            114  \n",
      "Israel                             114  \n",
      "Italy                              114  \n",
      "Japan                              114  \n",
      "Korea, Rep.                        114  \n",
      "Latvia                             114  \n",
      "Lithuania                          114  \n",
      "Luxembourg                         114  \n",
      "Malta                              114  \n",
      "Mexico                             114  \n",
      "Netherlands                        114  \n",
      "New Zealand                        114  \n",
      "Norway                             114  \n",
      "Peru                               114  \n",
      "Poland                             114  \n",
      "Portugal                           114  \n",
      "Romania                            114  \n",
      "Russian Federation                 114  \n",
      "Saudi Arabia                       114  \n",
      "Slovak Republic                    114  \n",
      "Slovenia                           114  \n",
      "South Africa                       114  \n",
      "Spain                              114  \n",
      "Sweden                             114  \n",
      "Switzerland                        114  \n",
      "Türkiye                            114  \n",
      "United Kingdom                     114  \n",
      "United States                      114  \n",
      "\n",
      "Unique indicators in the filtered dataset:\n",
      " 1. cc\n",
      " 2. ge\n",
      " 3. pv\n",
      " 4. rl\n",
      " 5. rq\n",
      " 6. va\n",
      "\n",
      "Sample of filtered data:\n",
      "     country  year indicator  estimate\n",
      "0  Argentina  1998        cc -0.203482\n",
      "1  Argentina  1998        ge  0.328712\n",
      "2  Argentina  1998        pv  -0.13465\n",
      "3  Argentina  1998        rl -0.038882\n",
      "4  Argentina  1998        rq  0.521346\n",
      "5  Argentina  1998        va   0.30885\n",
      "6  Argentina  2000        cc -0.172408\n",
      "7  Argentina  2000        ge -0.028039\n",
      "8  Argentina  2000        pv  0.095824\n",
      "9  Argentina  2000        rl -0.214404\n",
      "\n",
      "Filtered data saved to: Filtered_Governance_Data_1998_2018.xlsx\n",
      "\n",
      "Data availability analysis:\n",
      "Data points per country-year combination:\n",
      "Average data points per country-year: 6.0\n",
      "Countries with data for all years (21): 52\n",
      "\n",
      "Filtering completed successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Read the governance dataset\n",
    "input_file = '/kaggle/input/wgis-governance-1996-2023/Governance wgidataset with variable names.xlsx'\n",
    "\n",
    "print(\"Reading the governance dataset...\")\n",
    "# Read the Excel file (try different sheet names if needed)\n",
    "try:\n",
    "    df = pd.read_excel(input_file)\n",
    "    print(f\"Successfully read data with shape: {df.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error reading file: {e}\")\n",
    "    # Try reading all sheets to find the correct one\n",
    "    excel_file = pd.ExcelFile(input_file)\n",
    "    print(f\"Available sheets: {excel_file.sheet_names}\")\n",
    "    # Read the first sheet by default\n",
    "    df = pd.read_excel(input_file, sheet_name=excel_file.sheet_names[0])\n",
    "    print(f\"Read first sheet with shape: {df.shape}\")\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(f\"\\nDataset columns: {df.columns.tolist()}\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# Countries to filter (exactly as you specified)\n",
    "target_countries = [\n",
    "    'Argentina', 'Australia', 'Austria', 'Belgium', 'Brazil', 'Bulgaria',\n",
    "    'Canada', 'Chile', 'China', 'Colombia', 'Costa Rica', 'Croatia',\n",
    "    'Cyprus', 'Czech Republic', 'Denmark', 'Estonia', 'Finland', 'France',\n",
    "    'Germany', 'Greece', 'Hungary', 'Iceland', 'India', 'Indonesia',\n",
    "    'Ireland', 'Israel', 'Italy', 'Japan', 'Korea, Rep.', 'Latvia',\n",
    "    'Lithuania', 'Luxembourg', 'Malta', 'Mexico', 'Netherlands',\n",
    "    'New Zealand', 'Norway', 'Peru', 'Poland', 'Portugal', 'Romania',\n",
    "    'Russian Federation', 'Saudi Arabia', 'Slovak Republic', 'Slovenia', 'South Africa',\n",
    "    'Spain', 'Sweden', 'Switzerland', 'Türkiye', 'United Kingdom', 'United States'\n",
    "]\n",
    "\n",
    "# Years to filter\n",
    "target_years = list(range(1998, 2019))  # 1998 to 2018 inclusive\n",
    "\n",
    "print(f\"\\nTarget countries ({len(target_countries)}): {target_countries}\")\n",
    "print(f\"Target years: {min(target_years)} to {max(target_years)}\")\n",
    "\n",
    "# Function to find the correct column names (case-insensitive matching)\n",
    "def find_column(df, possible_names):\n",
    "    \"\"\"Find column name that matches any of the possible names (case-insensitive)\"\"\"\n",
    "    df_columns_lower = [col.lower() for col in df.columns]\n",
    "    for name in possible_names:\n",
    "        name_lower = name.lower()\n",
    "        if name_lower in df_columns_lower:\n",
    "            return df.columns[df_columns_lower.index(name_lower)]\n",
    "    return None\n",
    "\n",
    "# Find the correct column names\n",
    "country_col = find_column(df, ['country', 'countryname', 'country_name', 'nation'])\n",
    "year_col = find_column(df, ['year', 'time', 'date'])\n",
    "indicator_col = find_column(df, ['indicator', 'variable', 'measure'])\n",
    "estimate_col = find_column(df, ['estimate', 'value', 'score'])\n",
    "\n",
    "print(f\"\\nIdentified columns:\")\n",
    "print(f\"Country column: {country_col}\")\n",
    "print(f\"Year column: {year_col}\")\n",
    "print(f\"Indicator column: {indicator_col}\")\n",
    "print(f\"Estimate column: {estimate_col}\")\n",
    "\n",
    "# Check if all required columns are found\n",
    "missing_cols = []\n",
    "if not country_col:\n",
    "    missing_cols.append('country')\n",
    "if not year_col:\n",
    "    missing_cols.append('year')\n",
    "if not indicator_col:\n",
    "    missing_cols.append('indicator')\n",
    "if not estimate_col:\n",
    "    missing_cols.append('estimate')\n",
    "\n",
    "if missing_cols:\n",
    "    print(f\"\\nWarning: Could not find columns for: {missing_cols}\")\n",
    "    print(\"Available columns:\", df.columns.tolist())\n",
    "    \n",
    "    # Let user know they might need to specify column names manually\n",
    "    print(\"\\nPlease check the column names in your dataset and update the code accordingly.\")\n",
    "    print(\"You can manually set the column names like this:\")\n",
    "    print(\"country_col = 'YourCountryColumnName'\")\n",
    "    print(\"year_col = 'YourYearColumnName'\")\n",
    "    print(\"indicator_col = 'YourIndicatorColumnName'\")\n",
    "    print(\"estimate_col = 'YourEstimateColumnName'\")\n",
    "else:\n",
    "    # Proceed with filtering\n",
    "    print(f\"\\nFiltering data...\")\n",
    "    \n",
    "    # Check unique values in country and year columns\n",
    "    print(f\"Unique countries in dataset: {df[country_col].nunique()}\")\n",
    "    print(f\"Sample countries: {sorted(df[country_col].unique())[:10]}\")\n",
    "    print(f\"Year range in dataset: {df[year_col].min()} to {df[year_col].max()}\")\n",
    "    \n",
    "    # Filter for target countries and years\n",
    "    filtered_df = df[\n",
    "        (df[country_col].isin(target_countries)) & \n",
    "        (df[year_col].isin(target_years))\n",
    "    ].copy()\n",
    "    \n",
    "    print(f\"Data after country and year filtering: {filtered_df.shape}\")\n",
    "    \n",
    "    if filtered_df.empty:\n",
    "        print(\"No data found after filtering! Checking for country name mismatches...\")\n",
    "        \n",
    "        # Check for country name variations\n",
    "        unique_countries = sorted(df[country_col].unique())\n",
    "        print(\"All countries in dataset:\")\n",
    "        for country in unique_countries:\n",
    "            print(f\"  '{country}'\")\n",
    "        \n",
    "        # Look for potential matches\n",
    "        print(f\"\\nLooking for potential country name matches...\")\n",
    "        for target in target_countries:\n",
    "            matches = [country for country in unique_countries if target.lower() in country.lower() or country.lower() in target.lower()]\n",
    "            if matches:\n",
    "                print(f\"  {target} might match: {matches}\")\n",
    "    else:\n",
    "        # Keep only the required columns\n",
    "        columns_to_keep = [country_col, year_col, indicator_col, estimate_col]\n",
    "        filtered_df = filtered_df[columns_to_keep].copy()\n",
    "        \n",
    "        # Rename columns to standard names\n",
    "        filtered_df = filtered_df.rename(columns={\n",
    "            country_col: 'country',\n",
    "            year_col: 'year',\n",
    "            indicator_col: 'indicator',\n",
    "            estimate_col: 'estimate'\n",
    "        })\n",
    "        \n",
    "        # Remove any missing values in key columns\n",
    "        initial_rows = len(filtered_df)\n",
    "        filtered_df = filtered_df.dropna(subset=['country', 'year', 'indicator'])\n",
    "        final_rows = len(filtered_df)\n",
    "        \n",
    "        if initial_rows != final_rows:\n",
    "            print(f\"Removed {initial_rows - final_rows} rows with missing country/year/indicator data\")\n",
    "        \n",
    "        # Sort by country, year, and indicator\n",
    "        filtered_df = filtered_df.sort_values(['country', 'year', 'indicator']).reset_index(drop=True)\n",
    "        \n",
    "        print(f\"\\nFinal filtered dataset:\")\n",
    "        print(f\"Shape: {filtered_df.shape}\")\n",
    "        print(f\"Countries found: {filtered_df['country'].nunique()}\")\n",
    "        print(f\"Years covered: {filtered_df['year'].min()} to {filtered_df['year'].max()}\")\n",
    "        print(f\"Indicators: {filtered_df['indicator'].nunique()}\")\n",
    "        \n",
    "        # Show summary by country\n",
    "        country_summary = filtered_df.groupby('country').agg({\n",
    "            'year': ['min', 'max', 'nunique'],\n",
    "            'indicator': 'nunique',\n",
    "            'estimate': 'count'\n",
    "        }).round(2)\n",
    "        country_summary.columns = ['Min_Year', 'Max_Year', 'Years_Count', 'Indicators_Count', 'Total_Observations']\n",
    "        \n",
    "        print(f\"\\nSummary by country:\")\n",
    "        print(country_summary)\n",
    "        \n",
    "        # Show unique indicators\n",
    "        print(f\"\\nUnique indicators in the filtered dataset:\")\n",
    "        unique_indicators = sorted(filtered_df['indicator'].unique())\n",
    "        for i, indicator in enumerate(unique_indicators, 1):\n",
    "            print(f\"{i:2d}. {indicator}\")\n",
    "        \n",
    "        # Display sample data\n",
    "        print(f\"\\nSample of filtered data:\")\n",
    "        print(filtered_df.head(10))\n",
    "        \n",
    "        # Save the filtered dataset\n",
    "        output_file = 'Filtered_Governance_Data_1998_2018.xlsx'\n",
    "        \n",
    "        with pd.ExcelWriter(output_file) as writer:\n",
    "            # Main filtered data\n",
    "            filtered_df.to_excel(writer, sheet_name='Filtered_Data', index=False)\n",
    "            \n",
    "            # Country summary\n",
    "            country_summary.to_excel(writer, sheet_name='Country_Summary')\n",
    "            \n",
    "            # Indicator list\n",
    "            indicator_df = pd.DataFrame({'indicator': unique_indicators})\n",
    "            indicator_df.to_excel(writer, sheet_name='Indicators', index=False)\n",
    "        \n",
    "        print(f\"\\nFiltered data saved to: {output_file}\")\n",
    "        \n",
    "        # Data availability analysis\n",
    "        print(f\"\\nData availability analysis:\")\n",
    "        pivot_data = filtered_df.pivot_table(\n",
    "            values='estimate', \n",
    "            index='country', \n",
    "            columns='year', \n",
    "            aggfunc='count', \n",
    "            fill_value=0\n",
    "        )\n",
    "        \n",
    "        print(f\"Data points per country-year combination:\")\n",
    "        print(f\"Average data points per country-year: {pivot_data.values.mean():.1f}\")\n",
    "        print(f\"Countries with data for all years ({len(target_years)}): {(pivot_data > 0).all(axis=1).sum()}\")\n",
    "        \n",
    "        # Check for countries not found\n",
    "        found_countries = set(filtered_df['country'].unique())\n",
    "        missing_countries = set(target_countries) - found_countries\n",
    "        if missing_countries:\n",
    "            print(f\"\\nCountries not found in dataset: {sorted(missing_countries)}\")\n",
    "        \n",
    "        print(f\"\\nFiltering completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1daeae9b",
   "metadata": {
    "papermill": {
     "duration": 0.004364,
     "end_time": "2025-05-23T16:16:20.245842",
     "exception": false,
     "start_time": "2025-05-23T16:16:20.241478",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Filtering 52 Countries from 1998-2018 based on their indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f6fb55a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T16:16:20.257464Z",
     "iopub.status.busy": "2025-05-23T16:16:20.256938Z",
     "iopub.status.idle": "2025-05-23T16:16:23.725362Z",
     "shell.execute_reply": "2025-05-23T16:16:23.724333Z"
    },
    "papermill": {
     "duration": 3.476543,
     "end_time": "2025-05-23T16:16:23.727114",
     "exception": false,
     "start_time": "2025-05-23T16:16:20.250571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the Excel file...\n",
      "Original dataset shape: (32100, 9)\n",
      "Columns: ['countryname', 'year', 'indicator', 'estimate', 'stddev', 'nsource', 'pctrank', 'pctranklower', 'pctrankupper']\n",
      "Unique indicators found: ['cc' 'ge' 'pv' 'rl' 'rq' 'va']\n",
      "Filtering out rows with missing estimates...\n",
      "Dataset shape after removing missing estimates: (30974, 9)\n",
      "Pivoting data - converting indicators to columns...\n",
      "Final dataset shape: (5246, 8)\n",
      "Final columns: ['countryname', 'year', 'cc', 'ge', 'pv', 'rl', 'rq', 'va']\n",
      "\n",
      "==================================================\n",
      "TRANSFORMATION SUMMARY\n",
      "==================================================\n",
      "Total country-year observations: 5246\n",
      "Complete records (all 6 indicators): 5045\n",
      "\n",
      "Missing data by indicator:\n",
      "  cc: 103 missing values\n",
      "  ge: 127 missing values\n",
      "  pv: 68 missing values\n",
      "  rl: 13 missing values\n",
      "  rq: 125 missing values\n",
      "  va: 66 missing values\n",
      "\n",
      "First 5 rows of transformed data:\n",
      "   countryname  year        cc        ge        pv        rl        rq  \\\n",
      "0  Afghanistan  1996 -1.291705 -2.175167 -2.417310 -1.788075 -2.090330   \n",
      "1  Afghanistan  1998 -1.176012 -2.102292 -2.427355 -1.734887 -2.062872   \n",
      "2  Afghanistan  2000 -1.271724 -2.173946 -2.438969 -1.780661 -2.080253   \n",
      "3  Afghanistan  2002 -1.251137 -1.587687 -2.035034 -1.673473 -1.811546   \n",
      "4  Afghanistan  2003 -1.344180 -1.175768 -2.198372 -1.558294 -1.463108   \n",
      "\n",
      "         va  \n",
      "0 -1.908540  \n",
      "1 -2.039301  \n",
      "2 -2.031417  \n",
      "3 -1.433421  \n",
      "4 -1.177571  \n",
      "\n",
      "============================================================\n",
      "APPLYING FILTERS\n",
      "============================================================\n",
      "Filtering for 52 countries from 1998 to 2018\n",
      "Filtered dataset shape: (988, 8)\n",
      "\n",
      "Countries found in dataset: 52\n",
      "Countries not found in dataset: 0\n",
      "\n",
      "Filtered data saved to: governance_data_filtered.csv\n",
      "\n",
      "Sample of transformed data (10 rows):\n",
      "----------------------------------------------------------------------------------------------------\n",
      "    countryname  year     cc     ge     pv     rl     rq    va\n",
      "191   Argentina  1998 -0.203  0.329 -0.135 -0.039  0.521 0.309\n",
      "192   Argentina  2000 -0.172 -0.028  0.096 -0.214  0.182 0.418\n",
      "193   Argentina  2002 -0.417 -0.228 -0.777 -0.761 -0.881 0.260\n",
      "194   Argentina  2003 -0.480 -0.034 -0.360 -0.777 -0.691 0.349\n",
      "195   Argentina  2004 -0.414  0.015 -0.611 -0.767 -0.698 0.362\n",
      "196   Argentina  2005 -0.378 -0.098 -0.042 -0.558 -0.525 0.269\n",
      "197   Argentina  2006 -0.331 -0.034  0.002 -0.577 -0.615 0.403\n",
      "198   Argentina  2007 -0.372 -0.013  0.098 -0.601 -0.636 0.449\n",
      "199   Argentina  2008 -0.435 -0.124 -0.088 -0.700 -0.703 0.359\n",
      "200   Argentina  2009 -0.445 -0.294 -0.235 -0.694 -0.831 0.280\n",
      "\n",
      "============================================================\n",
      "FILTERED DATA ANALYSIS\n",
      "============================================================\n",
      "Actual year range in filtered data: 1998 - 2018\n",
      "\n",
      "Observations per country (1998-2018):\n",
      "  Argentina: 19 observations\n",
      "  Australia: 19 observations\n",
      "  Austria: 19 observations\n",
      "  Belgium: 19 observations\n",
      "  Brazil: 19 observations\n",
      "  Bulgaria: 19 observations\n",
      "  Canada: 19 observations\n",
      "  Chile: 19 observations\n",
      "  China: 19 observations\n",
      "  Colombia: 19 observations\n",
      "  Costa Rica: 19 observations\n",
      "  Croatia: 19 observations\n",
      "  Cyprus: 19 observations\n",
      "  Czech Republic: 19 observations\n",
      "  Denmark: 19 observations\n",
      "  Estonia: 19 observations\n",
      "  Finland: 19 observations\n",
      "  France: 19 observations\n",
      "  Germany: 19 observations\n",
      "  Greece: 19 observations\n",
      "  Hungary: 19 observations\n",
      "  Iceland: 19 observations\n",
      "  India: 19 observations\n",
      "  Indonesia: 19 observations\n",
      "  Ireland: 19 observations\n",
      "  Israel: 19 observations\n",
      "  Italy: 19 observations\n",
      "  Japan: 19 observations\n",
      "  Korea, Rep.: 19 observations\n",
      "  Latvia: 19 observations\n",
      "  Lithuania: 19 observations\n",
      "  Luxembourg: 19 observations\n",
      "  Malta: 19 observations\n",
      "  Mexico: 19 observations\n",
      "  Netherlands: 19 observations\n",
      "  New Zealand: 19 observations\n",
      "  Norway: 19 observations\n",
      "  Peru: 19 observations\n",
      "  Poland: 19 observations\n",
      "  Portugal: 19 observations\n",
      "  Romania: 19 observations\n",
      "  Russian Federation: 19 observations\n",
      "  Saudi Arabia: 19 observations\n",
      "  Slovak Republic: 19 observations\n",
      "  Slovenia: 19 observations\n",
      "  South Africa: 19 observations\n",
      "  Spain: 19 observations\n",
      "  Sweden: 19 observations\n",
      "  Switzerland: 19 observations\n",
      "  Türkiye: 19 observations\n",
      "  United Kingdom: 19 observations\n",
      "  United States: 19 observations\n",
      "\n",
      "Complete records in filtered data: 988 out of 988\n",
      "\n",
      "Missing data by indicator (filtered dataset):\n",
      "  cc: 0 missing (0.0%)\n",
      "  ge: 0 missing (0.0%)\n",
      "  pv: 0 missing (0.0%)\n",
      "  rl: 0 missing (0.0%)\n",
      "  rq: 0 missing (0.0%)\n",
      "  va: 0 missing (0.0%)\n",
      "\n",
      "Governance indicators summary (filtered data):\n",
      "            cc       ge       pv       rl       rq       va\n",
      "count  988.000  988.000  988.000  988.000  988.000  988.000\n",
      "mean     0.817    0.913    0.438    0.845    0.938    0.837\n",
      "std      0.953    0.767    0.816    0.854    0.682    0.744\n",
      "min     -1.160   -0.757   -2.376   -1.084   -1.066   -1.907\n",
      "25%      0.005    0.236    0.004    0.097    0.451    0.529\n",
      "50%      0.770    0.977    0.632    0.976    1.061    1.029\n",
      "75%      1.746    1.621    1.042    1.666    1.519    1.370\n",
      "max      2.459    2.347    1.759    2.125    2.082    1.801\n",
      "\n",
      "Complete records only saved to: governance_data_filtered_complete.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# After running the main transformation:\\n# Filter by year range\\nrecent_data = filter_by_year_range(transformed_df, 2010, 2020)\\n\\n# Filter by specific countries\\ncountries_of_interest = [\\'United States\\', \\'China\\', \\'Germany\\', \\'Brazil\\', \\'India\\']\\ncountry_subset = filter_by_countries(transformed_df, countries_of_interest)\\n\\n# Export only complete records\\ncomplete_data = export_complete_records_only(transformed_df, \"governance_complete_records.csv\")\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def transform_governance_data(input_file, output_file=None):\n",
    "    \"\"\"\n",
    "    Transform governance dataset by pivoting indicators into separate columns.\n",
    "    \n",
    "    Parameters:\n",
    "    input_file (str): Path to the input Excel file\n",
    "    output_file (str): Path for the output CSV file (optional)\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: Transformed dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read the Excel file\n",
    "    print(\"Reading the Excel file...\")\n",
    "    df = pd.read_excel(input_file, sheet_name=0)  # Read first sheet\n",
    "    \n",
    "    print(f\"Original dataset shape: {df.shape}\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "    \n",
    "    # Display unique indicators\n",
    "    unique_indicators = df['indicator'].unique()\n",
    "    print(f\"Unique indicators found: {unique_indicators}\")\n",
    "    \n",
    "    # Filter out rows with missing estimates (marked as \"..\" or actual NaN)\n",
    "    print(\"Filtering out rows with missing estimates...\")\n",
    "    df_clean = df[df['estimate'] != '..'].copy()\n",
    "    df_clean = df_clean.dropna(subset=['estimate'])\n",
    "    \n",
    "    print(f\"Dataset shape after removing missing estimates: {df_clean.shape}\")\n",
    "    \n",
    "    # Convert estimate to numeric if it's not already\n",
    "    df_clean['estimate'] = pd.to_numeric(df_clean['estimate'], errors='coerce')\n",
    "    \n",
    "    # Remove any rows where estimate conversion failed\n",
    "    df_clean = df_clean.dropna(subset=['estimate'])\n",
    "    \n",
    "    # Pivot the data: indicators become columns with their estimate values\n",
    "    print(\"Pivoting data - converting indicators to columns...\")\n",
    "    df_pivoted = df_clean.pivot_table(\n",
    "        index=['countryname', 'year'], \n",
    "        columns='indicator', \n",
    "        values='estimate',\n",
    "        aggfunc='first'  # In case of duplicates, take the first value\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Flatten column names (remove the multi-level index)\n",
    "    df_pivoted.columns.name = None\n",
    "    \n",
    "    # Reorder columns: countryname, year, then indicators in alphabetical order\n",
    "    indicator_columns = [col for col in df_pivoted.columns if col not in ['countryname', 'year']]\n",
    "    indicator_columns.sort()  # Sort indicators alphabetically\n",
    "    \n",
    "    final_columns = ['countryname', 'year'] + indicator_columns\n",
    "    df_final = df_pivoted[final_columns].copy()\n",
    "    \n",
    "    print(f\"Final dataset shape: {df_final.shape}\")\n",
    "    print(f\"Final columns: {list(df_final.columns)}\")\n",
    "    \n",
    "    # Display summary statistics\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"TRANSFORMATION SUMMARY\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Total country-year observations: {len(df_final)}\")\n",
    "    \n",
    "    # Check how many rows have all indicators\n",
    "    complete_rows = df_final.dropna()\n",
    "    print(f\"Complete records (all 6 indicators): {len(complete_rows)}\")\n",
    "    \n",
    "    # Show missing data by indicator\n",
    "    print(\"\\nMissing data by indicator:\")\n",
    "    for col in indicator_columns:\n",
    "        missing_count = df_final[col].isna().sum()\n",
    "        print(f\"  {col}: {missing_count} missing values\")\n",
    "    \n",
    "    # Display first few rows\n",
    "    print(f\"\\nFirst 5 rows of transformed data:\")\n",
    "    print(df_final.head())\n",
    "    \n",
    "    # Save to CSV if output file is specified\n",
    "    if output_file:\n",
    "        df_final.to_csv(output_file, index=False)\n",
    "        print(f\"\\nTransformed data saved to: {output_file}\")\n",
    "    \n",
    "    return df_final\n",
    "\n",
    "def display_sample_data(df, n_rows=10):\n",
    "    \"\"\"\n",
    "    Display sample data with better formatting.\n",
    "    \"\"\"\n",
    "    print(f\"\\nSample of transformed data ({n_rows} rows):\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    # Create a formatted display\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "    pd.set_option('display.float_format', '{:.3f}'.format)\n",
    "    \n",
    "    print(df.head(n_rows))\n",
    "    \n",
    "    # Reset display options\n",
    "    pd.reset_option('display.max_columns')\n",
    "    pd.reset_option('display.width')\n",
    "    pd.reset_option('display.float_format')\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Specify your file paths\n",
    "    input_file = '/kaggle/input/wgis-governance-1996-2023/Governance wgidataset with variable names.xlsx'\n",
    "    output_file = \"governance_data_filtered.csv\"\n",
    "    \n",
    "    # Define the countries to filter\n",
    "    selected_countries = [\n",
    "        'Argentina', 'Australia', 'Austria', 'Belgium', 'Brazil', 'Bulgaria', \n",
    "        'Canada', 'Chile', 'China', 'Colombia', 'Costa Rica', 'Croatia', \n",
    "        'Cyprus', 'Czech Republic', 'Denmark', 'Estonia', 'Finland', 'France', \n",
    "        'Germany', 'Greece', 'Hungary', 'Iceland', 'India', 'Indonesia', \n",
    "        'Ireland', 'Israel', 'Italy', 'Japan', 'Korea, Rep.', 'Latvia', \n",
    "        'Lithuania', 'Luxembourg', 'Malta', 'Mexico', 'Netherlands', \n",
    "        'New Zealand', 'Norway', 'Peru', 'Poland', 'Portugal', 'Romania', \n",
    "        'Russian Federation', 'Saudi Arabia', 'Slovak Republic', 'Slovenia', \n",
    "        'South Africa', 'Spain', 'Sweden', 'Switzerland', 'Türkiye', \n",
    "        'United Kingdom', 'United States'\n",
    "    ]\n",
    "    \n",
    "    # Define year range\n",
    "    start_year = 1998\n",
    "    end_year = 2018\n",
    "    \n",
    "    try:\n",
    "        # Transform the data\n",
    "        transformed_df = transform_governance_data(input_file)\n",
    "        \n",
    "        # Apply filters\n",
    "        print(f\"\\n\" + \"=\"*60)\n",
    "        print(\"APPLYING FILTERS\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Filtering for {len(selected_countries)} countries from {start_year} to {end_year}\")\n",
    "        \n",
    "        # Filter by countries and year range\n",
    "        filtered_df = transformed_df[\n",
    "            (transformed_df['countryname'].isin(selected_countries)) &\n",
    "            (transformed_df['year'] >= start_year) &\n",
    "            (transformed_df['year'] <= end_year)\n",
    "        ].copy()\n",
    "        \n",
    "        print(f\"Filtered dataset shape: {filtered_df.shape}\")\n",
    "        \n",
    "        # Check which countries from our list are actually in the data\n",
    "        available_countries = set(filtered_df['countryname'].unique())\n",
    "        requested_countries = set(selected_countries)\n",
    "        found_countries = available_countries.intersection(requested_countries)\n",
    "        missing_countries = requested_countries - available_countries\n",
    "        \n",
    "        print(f\"\\nCountries found in dataset: {len(found_countries)}\")\n",
    "        print(f\"Countries not found in dataset: {len(missing_countries)}\")\n",
    "        \n",
    "        if missing_countries:\n",
    "            print(f\"Missing countries: {sorted(list(missing_countries))}\")\n",
    "        \n",
    "        # Save filtered data\n",
    "        filtered_df.to_csv(output_file, index=False)\n",
    "        print(f\"\\nFiltered data saved to: {output_file}\")\n",
    "        \n",
    "        # Display sample of the filtered data\n",
    "        display_sample_data(filtered_df)\n",
    "        \n",
    "        # Additional analysis for filtered data\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"FILTERED DATA ANALYSIS\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Year range in filtered data\n",
    "        actual_year_range = f\"{filtered_df['year'].min()} - {filtered_df['year'].max()}\"\n",
    "        print(f\"Actual year range in filtered data: {actual_year_range}\")\n",
    "        \n",
    "        # Number of observations per country\n",
    "        country_obs = filtered_df['countryname'].value_counts().sort_index()\n",
    "        print(f\"\\nObservations per country ({start_year}-{end_year}):\")\n",
    "        for country, count in country_obs.items():\n",
    "            print(f\"  {country}: {count} observations\")\n",
    "        \n",
    "        # Check for complete records (all 6 indicators)\n",
    "        complete_filtered = filtered_df.dropna()\n",
    "        print(f\"\\nComplete records in filtered data: {len(complete_filtered)} out of {len(filtered_df)}\")\n",
    "        \n",
    "        # Missing data by indicator in filtered dataset\n",
    "        print(f\"\\nMissing data by indicator (filtered dataset):\")\n",
    "        indicator_cols = [col for col in filtered_df.columns if col not in ['countryname', 'year']]\n",
    "        for col in indicator_cols:\n",
    "            missing_count = filtered_df[col].isna().sum()\n",
    "            missing_pct = (missing_count / len(filtered_df)) * 100\n",
    "            print(f\"  {col}: {missing_count} missing ({missing_pct:.1f}%)\")\n",
    "        \n",
    "        # Summary statistics for filtered data\n",
    "        print(f\"\\nGovernance indicators summary (filtered data):\")\n",
    "        print(filtered_df[indicator_cols].describe().round(3))\n",
    "        \n",
    "        # Optional: Save complete records only\n",
    "        complete_output_file = \"governance_data_filtered_complete.csv\"\n",
    "        if len(complete_filtered) > 0:\n",
    "            complete_filtered.to_csv(complete_output_file, index=False)\n",
    "            print(f\"\\nComplete records only saved to: {complete_output_file}\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Could not find the file '{input_file}'\")\n",
    "        print(\"Please make sure the file exists in the current directory.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "\n",
    "# Additional utility functions\n",
    "\n",
    "def filter_by_year_range(df, start_year, end_year):\n",
    "    \"\"\"\n",
    "    Filter the transformed dataset by year range.\n",
    "    \"\"\"\n",
    "    filtered_df = df[(df['year'] >= start_year) & (df['year'] <= end_year)]\n",
    "    print(f\"Filtered data ({start_year}-{end_year}): {len(filtered_df)} rows\")\n",
    "    return filtered_df\n",
    "\n",
    "def filter_by_countries(df, country_list):\n",
    "    \"\"\"\n",
    "    Filter the transformed dataset by specific countries.\n",
    "    \"\"\"\n",
    "    filtered_df = df[df['countryname'].isin(country_list)]\n",
    "    print(f\"Filtered data for {len(country_list)} countries: {len(filtered_df)} rows\")\n",
    "    return filtered_df\n",
    "\n",
    "def export_complete_records_only(df, output_file):\n",
    "    \"\"\"\n",
    "    Export only records that have all 6 governance indicators.\n",
    "    \"\"\"\n",
    "    complete_df = df.dropna()\n",
    "    complete_df.to_csv(output_file, index=False)\n",
    "    print(f\"Complete records only ({len(complete_df)} rows) saved to: {output_file}\")\n",
    "    return complete_df\n",
    "\n",
    "# Example usage of utility functions:\n",
    "\"\"\"\n",
    "# After running the main transformation:\n",
    "# Filter by year range\n",
    "recent_data = filter_by_year_range(transformed_df, 2010, 2020)\n",
    "\n",
    "# Filter by specific countries\n",
    "countries_of_interest = ['United States', 'China', 'Germany', 'Brazil', 'India']\n",
    "country_subset = filter_by_countries(transformed_df, countries_of_interest)\n",
    "\n",
    "# Export only complete records\n",
    "complete_data = export_complete_records_only(transformed_df, \"governance_complete_records.csv\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac72ff3",
   "metadata": {
    "papermill": {
     "duration": 0.004746,
     "end_time": "2025-05-23T16:16:23.737062",
     "exception": false,
     "start_time": "2025-05-23T16:16:23.732316",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Predicting and Filling the missing 1999's data for every indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a7d2116",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T16:16:23.748768Z",
     "iopub.status.busy": "2025-05-23T16:16:23.748416Z",
     "iopub.status.idle": "2025-05-23T16:16:27.208707Z",
     "shell.execute_reply": "2025-05-23T16:16:27.207546Z"
    },
    "papermill": {
     "duration": 3.468592,
     "end_time": "2025-05-23T16:16:27.210599",
     "exception": false,
     "start_time": "2025-05-23T16:16:23.742007",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the Excel file...\n",
      "Original dataset shape: (32100, 9)\n",
      "Columns: ['countryname', 'year', 'indicator', 'estimate', 'stddev', 'nsource', 'pctrank', 'pctranklower', 'pctrankupper']\n",
      "Unique indicators found: ['cc' 'ge' 'pv' 'rl' 'rq' 'va']\n",
      "Filtering out rows with missing estimates...\n",
      "Dataset shape after removing missing estimates: (30974, 9)\n",
      "Pivoting data - converting indicators to columns...\n",
      "Final dataset shape: (5246, 8)\n",
      "Final columns: ['countryname', 'year', 'cc', 'ge', 'pv', 'rl', 'rq', 'va']\n",
      "\n",
      "==================================================\n",
      "TRANSFORMATION SUMMARY\n",
      "==================================================\n",
      "Total country-year observations: 5246\n",
      "Complete records (all 6 indicators): 5045\n",
      "\n",
      "Missing data by indicator:\n",
      "  cc: 103 missing values\n",
      "  ge: 127 missing values\n",
      "  pv: 68 missing values\n",
      "  rl: 13 missing values\n",
      "  rq: 125 missing values\n",
      "  va: 66 missing values\n",
      "\n",
      "First 5 rows of transformed data:\n",
      "   countryname  year        cc        ge        pv        rl        rq  \\\n",
      "0  Afghanistan  1996 -1.291705 -2.175167 -2.417310 -1.788075 -2.090330   \n",
      "1  Afghanistan  1998 -1.176012 -2.102292 -2.427355 -1.734887 -2.062872   \n",
      "2  Afghanistan  2000 -1.271724 -2.173946 -2.438969 -1.780661 -2.080253   \n",
      "3  Afghanistan  2002 -1.251137 -1.587687 -2.035034 -1.673473 -1.811546   \n",
      "4  Afghanistan  2003 -1.344180 -1.175768 -2.198372 -1.558294 -1.463108   \n",
      "\n",
      "         va  \n",
      "0 -1.908540  \n",
      "1 -2.039301  \n",
      "2 -2.031417  \n",
      "3 -1.433421  \n",
      "4 -1.177571  \n",
      "\n",
      "============================================================\n",
      "APPLYING FILTERS\n",
      "============================================================\n",
      "Filtering for 52 countries from 1998 to 2018\n",
      "\n",
      "============================================================\n",
      "HANDLING MISSING 1999 DATA\n",
      "============================================================\n",
      "Existing 1999 records: 0\n",
      "No 1999 data found. Creating interpolated values...\n",
      "Interpolating 1999 data for 52 countries...\n",
      "  Argentina: Interpolated 6/6 indicators\n",
      "  Australia: Interpolated 6/6 indicators\n",
      "  Austria: Interpolated 6/6 indicators\n",
      "  Belgium: Interpolated 6/6 indicators\n",
      "  Brazil: Interpolated 6/6 indicators\n",
      "  Bulgaria: Interpolated 6/6 indicators\n",
      "  Canada: Interpolated 6/6 indicators\n",
      "  Chile: Interpolated 6/6 indicators\n",
      "  China: Interpolated 6/6 indicators\n",
      "  Colombia: Interpolated 6/6 indicators\n",
      "  Costa Rica: Interpolated 6/6 indicators\n",
      "  Croatia: Interpolated 6/6 indicators\n",
      "  Cyprus: Interpolated 6/6 indicators\n",
      "  Czech Republic: Interpolated 6/6 indicators\n",
      "  Denmark: Interpolated 6/6 indicators\n",
      "  Estonia: Interpolated 6/6 indicators\n",
      "  Finland: Interpolated 6/6 indicators\n",
      "  France: Interpolated 6/6 indicators\n",
      "  Germany: Interpolated 6/6 indicators\n",
      "  Greece: Interpolated 6/6 indicators\n",
      "  Hungary: Interpolated 6/6 indicators\n",
      "  Iceland: Interpolated 6/6 indicators\n",
      "  India: Interpolated 6/6 indicators\n",
      "  Indonesia: Interpolated 6/6 indicators\n",
      "  Ireland: Interpolated 6/6 indicators\n",
      "  Israel: Interpolated 6/6 indicators\n",
      "  Italy: Interpolated 6/6 indicators\n",
      "  Japan: Interpolated 6/6 indicators\n",
      "  Korea, Rep.: Interpolated 6/6 indicators\n",
      "  Latvia: Interpolated 6/6 indicators\n",
      "  Lithuania: Interpolated 6/6 indicators\n",
      "  Luxembourg: Interpolated 6/6 indicators\n",
      "  Malta: Interpolated 6/6 indicators\n",
      "  Mexico: Interpolated 6/6 indicators\n",
      "  Netherlands: Interpolated 6/6 indicators\n",
      "  New Zealand: Interpolated 6/6 indicators\n",
      "  Norway: Interpolated 6/6 indicators\n",
      "  Peru: Interpolated 6/6 indicators\n",
      "  Poland: Interpolated 6/6 indicators\n",
      "  Portugal: Interpolated 6/6 indicators\n",
      "  Romania: Interpolated 6/6 indicators\n",
      "  Russian Federation: Interpolated 6/6 indicators\n",
      "  Saudi Arabia: Interpolated 6/6 indicators\n",
      "  Slovak Republic: Interpolated 6/6 indicators\n",
      "  Slovenia: Interpolated 6/6 indicators\n",
      "  South Africa: Interpolated 6/6 indicators\n",
      "  Spain: Interpolated 6/6 indicators\n",
      "  Sweden: Interpolated 6/6 indicators\n",
      "  Switzerland: Interpolated 6/6 indicators\n",
      "  Türkiye: Interpolated 6/6 indicators\n",
      "  United Kingdom: Interpolated 6/6 indicators\n",
      "  United States: Interpolated 6/6 indicators\n",
      "\n",
      "Added 52 interpolated 1999 records\n",
      "Filtered dataset shape: (1040, 8)\n",
      "\n",
      "Countries found in dataset: 52\n",
      "Countries not found in dataset: 0\n",
      "\n",
      "Filtered data saved to: governance_data_filtered.csv\n",
      "\n",
      "Sample of transformed data (10 rows):\n",
      "----------------------------------------------------------------------------------------------------\n",
      "  countryname  year     cc     ge     pv     rl     rq    va\n",
      "0   Argentina  1998 -0.203  0.329 -0.135 -0.039  0.521 0.309\n",
      "1   Argentina  1999 -0.188  0.150 -0.019 -0.127  0.352 0.364\n",
      "2   Argentina  2000 -0.172 -0.028  0.096 -0.214  0.182 0.418\n",
      "3   Argentina  2002 -0.417 -0.228 -0.777 -0.761 -0.881 0.260\n",
      "4   Argentina  2003 -0.480 -0.034 -0.360 -0.777 -0.691 0.349\n",
      "5   Argentina  2004 -0.414  0.015 -0.611 -0.767 -0.698 0.362\n",
      "6   Argentina  2005 -0.378 -0.098 -0.042 -0.558 -0.525 0.269\n",
      "7   Argentina  2006 -0.331 -0.034  0.002 -0.577 -0.615 0.403\n",
      "8   Argentina  2007 -0.372 -0.013  0.098 -0.601 -0.636 0.449\n",
      "9   Argentina  2008 -0.435 -0.124 -0.088 -0.700 -0.703 0.359\n",
      "\n",
      "============================================================\n",
      "FILTERED DATA ANALYSIS\n",
      "============================================================\n",
      "Actual year range in filtered data: 1998 - 2018\n",
      "\n",
      "Observations per country (1998-2018):\n",
      "  Argentina: 20 observations\n",
      "  Australia: 20 observations\n",
      "  Austria: 20 observations\n",
      "  Belgium: 20 observations\n",
      "  Brazil: 20 observations\n",
      "  Bulgaria: 20 observations\n",
      "  Canada: 20 observations\n",
      "  Chile: 20 observations\n",
      "  China: 20 observations\n",
      "  Colombia: 20 observations\n",
      "  Costa Rica: 20 observations\n",
      "  Croatia: 20 observations\n",
      "  Cyprus: 20 observations\n",
      "  Czech Republic: 20 observations\n",
      "  Denmark: 20 observations\n",
      "  Estonia: 20 observations\n",
      "  Finland: 20 observations\n",
      "  France: 20 observations\n",
      "  Germany: 20 observations\n",
      "  Greece: 20 observations\n",
      "  Hungary: 20 observations\n",
      "  Iceland: 20 observations\n",
      "  India: 20 observations\n",
      "  Indonesia: 20 observations\n",
      "  Ireland: 20 observations\n",
      "  Israel: 20 observations\n",
      "  Italy: 20 observations\n",
      "  Japan: 20 observations\n",
      "  Korea, Rep.: 20 observations\n",
      "  Latvia: 20 observations\n",
      "  Lithuania: 20 observations\n",
      "  Luxembourg: 20 observations\n",
      "  Malta: 20 observations\n",
      "  Mexico: 20 observations\n",
      "  Netherlands: 20 observations\n",
      "  New Zealand: 20 observations\n",
      "  Norway: 20 observations\n",
      "  Peru: 20 observations\n",
      "  Poland: 20 observations\n",
      "  Portugal: 20 observations\n",
      "  Romania: 20 observations\n",
      "  Russian Federation: 20 observations\n",
      "  Saudi Arabia: 20 observations\n",
      "  Slovak Republic: 20 observations\n",
      "  Slovenia: 20 observations\n",
      "  South Africa: 20 observations\n",
      "  Spain: 20 observations\n",
      "  Sweden: 20 observations\n",
      "  Switzerland: 20 observations\n",
      "  Türkiye: 20 observations\n",
      "  United Kingdom: 20 observations\n",
      "  United States: 20 observations\n",
      "\n",
      "Complete records in filtered data: 1040 out of 1040\n",
      "\n",
      "Missing data by indicator (filtered dataset):\n",
      "  cc: 0 missing (0.0%)\n",
      "  ge: 0 missing (0.0%)\n",
      "  pv: 0 missing (0.0%)\n",
      "  rl: 0 missing (0.0%)\n",
      "  rq: 0 missing (0.0%)\n",
      "  va: 0 missing (0.0%)\n",
      "\n",
      "Governance indicators summary (filtered data):\n",
      "             cc        ge        pv        rl        rq        va\n",
      "count  1040.000  1040.000  1040.000  1040.000  1040.000  1040.000\n",
      "mean      0.819     0.912     0.443     0.843     0.934     0.836\n",
      "std       0.953     0.770     0.821     0.855     0.680     0.745\n",
      "min      -1.160    -0.757    -2.376    -1.084    -1.066    -1.907\n",
      "25%       0.005     0.222     0.006     0.097     0.450     0.528\n",
      "50%       0.763     0.975     0.633     0.976     1.055     1.031\n",
      "75%       1.746     1.629     1.051     1.666     1.513     1.370\n",
      "max       2.459     2.347     1.759     2.125     2.082     1.801\n",
      "\n",
      "Complete records only saved to: governance_data_filtered_complete.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# After running the main transformation:\\n# Filter by year range\\nrecent_data = filter_by_year_range(transformed_df, 2010, 2020)\\n\\n# Filter by specific countries\\ncountries_of_interest = [\\'United States\\', \\'China\\', \\'Germany\\', \\'Brazil\\', \\'India\\']\\ncountry_subset = filter_by_countries(transformed_df, countries_of_interest)\\n\\n# Export only complete records\\ncomplete_data = export_complete_records_only(transformed_df, \"governance_complete_records.csv\")\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def interpolate_missing_1999(df, countries_to_interpolate):\n",
    "    \"\"\"\n",
    "    Interpolate missing 1999 data for specified countries based on surrounding years.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The filtered dataset\n",
    "    countries_to_interpolate (list): List of countries missing 1999 data\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: Dataset with interpolated 1999 data\n",
    "    \"\"\"\n",
    "    print(f\"Interpolating 1999 data for {len(countries_to_interpolate)} countries...\")\n",
    "    \n",
    "    # Get indicator columns (excluding countryname and year)\n",
    "    indicator_cols = [col for col in df.columns if col not in ['countryname', 'year']]\n",
    "    \n",
    "    # Create list to store new 1999 rows\n",
    "    new_1999_rows = []\n",
    "    \n",
    "    for country in countries_to_interpolate:\n",
    "        country_data = df[df['countryname'] == country].copy()\n",
    "        \n",
    "        if len(country_data) == 0:\n",
    "            print(f\"  Warning: No data found for {country}\")\n",
    "            continue\n",
    "            \n",
    "        # Get 1998 and 2000 data for interpolation\n",
    "        data_1998 = country_data[country_data['year'] == 1998]\n",
    "        data_2000 = country_data[country_data['year'] == 2000]\n",
    "        \n",
    "        # Create new 1999 row\n",
    "        new_row = {'countryname': country, 'year': 1999}\n",
    "        \n",
    "        interpolated_indicators = 0\n",
    "        \n",
    "        for indicator in indicator_cols:\n",
    "            val_1998 = data_1998[indicator].iloc[0] if len(data_1998) > 0 and not pd.isna(data_1998[indicator].iloc[0]) else None\n",
    "            val_2000 = data_2000[indicator].iloc[0] if len(data_2000) > 0 and not pd.isna(data_2000[indicator].iloc[0]) else None\n",
    "            \n",
    "            if val_1998 is not None and val_2000 is not None:\n",
    "                # Linear interpolation: average of 1998 and 2000\n",
    "                interpolated_value = (val_1998 + val_2000) / 2\n",
    "                new_row[indicator] = interpolated_value\n",
    "                interpolated_indicators += 1\n",
    "            elif val_1998 is not None:\n",
    "                # Use 1998 value if 2000 is missing\n",
    "                new_row[indicator] = val_1998\n",
    "                interpolated_indicators += 1\n",
    "            elif val_2000 is not None:\n",
    "                # Use 2000 value if 1998 is missing\n",
    "                new_row[indicator] = val_2000\n",
    "                interpolated_indicators += 1\n",
    "            else:\n",
    "                # Both years missing, try to find nearest available data\n",
    "                nearest_value = find_nearest_value(country_data, indicator, 1999)\n",
    "                new_row[indicator] = nearest_value\n",
    "                if nearest_value is not None:\n",
    "                    interpolated_indicators += 1\n",
    "        \n",
    "        if interpolated_indicators > 0:\n",
    "            new_1999_rows.append(new_row)\n",
    "            print(f\"  {country}: Interpolated {interpolated_indicators}/{len(indicator_cols)} indicators\")\n",
    "        else:\n",
    "            print(f\"  {country}: Could not interpolate any indicators (insufficient data)\")\n",
    "    \n",
    "    # Add new 1999 rows to the dataframe\n",
    "    if new_1999_rows:\n",
    "        new_1999_df = pd.DataFrame(new_1999_rows)\n",
    "        df_with_1999 = pd.concat([df, new_1999_df], ignore_index=True)\n",
    "        df_with_1999 = df_with_1999.sort_values(['countryname', 'year']).reset_index(drop=True)\n",
    "        \n",
    "        print(f\"\\nAdded {len(new_1999_rows)} interpolated 1999 records\")\n",
    "        return df_with_1999\n",
    "    else:\n",
    "        print(\"\\nNo 1999 records were added\")\n",
    "        return df\n",
    "\n",
    "def find_nearest_value(country_data, indicator, target_year):\n",
    "    \"\"\"\n",
    "    Find the nearest available value for an indicator around the target year.\n",
    "    \"\"\"\n",
    "    # Get all available years for this country and indicator\n",
    "    available_data = country_data.dropna(subset=[indicator])\n",
    "    \n",
    "    if len(available_data) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Find the closest year\n",
    "    available_data['year_diff'] = abs(available_data['year'] - target_year)\n",
    "    closest_row = available_data.loc[available_data['year_diff'].idxmin()]\n",
    "    \n",
    "    return closest_row[indicator]\n",
    "\n",
    "def transform_governance_data(input_file, output_file=None):\n",
    "    \"\"\"\n",
    "    Transform governance dataset by pivoting indicators into separate columns.\n",
    "    \n",
    "    Parameters:\n",
    "    input_file (str): Path to the input Excel file\n",
    "    output_file (str): Path for the output CSV file (optional)\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: Transformed dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read the Excel file\n",
    "    print(\"Reading the Excel file...\")\n",
    "    df = pd.read_excel(input_file, sheet_name=0)  # Read first sheet\n",
    "    \n",
    "    print(f\"Original dataset shape: {df.shape}\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "    \n",
    "    # Display unique indicators\n",
    "    unique_indicators = df['indicator'].unique()\n",
    "    print(f\"Unique indicators found: {unique_indicators}\")\n",
    "    \n",
    "    # Filter out rows with missing estimates (marked as \"..\" or actual NaN)\n",
    "    print(\"Filtering out rows with missing estimates...\")\n",
    "    df_clean = df[df['estimate'] != '..'].copy()\n",
    "    df_clean = df_clean.dropna(subset=['estimate'])\n",
    "    \n",
    "    print(f\"Dataset shape after removing missing estimates: {df_clean.shape}\")\n",
    "    \n",
    "    # Convert estimate to numeric if it's not already\n",
    "    df_clean['estimate'] = pd.to_numeric(df_clean['estimate'], errors='coerce')\n",
    "    \n",
    "    # Remove any rows where estimate conversion failed\n",
    "    df_clean = df_clean.dropna(subset=['estimate'])\n",
    "    \n",
    "    # Pivot the data: indicators become columns with their estimate values\n",
    "    print(\"Pivoting data - converting indicators to columns...\")\n",
    "    df_pivoted = df_clean.pivot_table(\n",
    "        index=['countryname', 'year'], \n",
    "        columns='indicator', \n",
    "        values='estimate',\n",
    "        aggfunc='first'  # In case of duplicates, take the first value\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Flatten column names (remove the multi-level index)\n",
    "    df_pivoted.columns.name = None\n",
    "    \n",
    "    # Reorder columns: countryname, year, then indicators in alphabetical order\n",
    "    indicator_columns = [col for col in df_pivoted.columns if col not in ['countryname', 'year']]\n",
    "    indicator_columns.sort()  # Sort indicators alphabetically\n",
    "    \n",
    "    final_columns = ['countryname', 'year'] + indicator_columns\n",
    "    df_final = df_pivoted[final_columns].copy()\n",
    "    \n",
    "    print(f\"Final dataset shape: {df_final.shape}\")\n",
    "    print(f\"Final columns: {list(df_final.columns)}\")\n",
    "    \n",
    "    # Display summary statistics\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"TRANSFORMATION SUMMARY\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Total country-year observations: {len(df_final)}\")\n",
    "    \n",
    "    # Check how many rows have all indicators\n",
    "    complete_rows = df_final.dropna()\n",
    "    print(f\"Complete records (all 6 indicators): {len(complete_rows)}\")\n",
    "    \n",
    "    # Show missing data by indicator\n",
    "    print(\"\\nMissing data by indicator:\")\n",
    "    for col in indicator_columns:\n",
    "        missing_count = df_final[col].isna().sum()\n",
    "        print(f\"  {col}: {missing_count} missing values\")\n",
    "    \n",
    "    # Display first few rows\n",
    "    print(f\"\\nFirst 5 rows of transformed data:\")\n",
    "    print(df_final.head())\n",
    "    \n",
    "    # Save to CSV if output file is specified\n",
    "    if output_file:\n",
    "        df_final.to_csv(output_file, index=False)\n",
    "        print(f\"\\nTransformed data saved to: {output_file}\")\n",
    "    \n",
    "    return df_final\n",
    "\n",
    "def display_sample_data(df, n_rows=10):\n",
    "    \"\"\"\n",
    "    Display sample data with better formatting.\n",
    "    \"\"\"\n",
    "    print(f\"\\nSample of transformed data ({n_rows} rows):\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    # Create a formatted display\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "    pd.set_option('display.float_format', '{:.3f}'.format)\n",
    "    \n",
    "    print(df.head(n_rows))\n",
    "    \n",
    "    # Reset display options\n",
    "    pd.reset_option('display.max_columns')\n",
    "    pd.reset_option('display.width')\n",
    "    pd.reset_option('display.float_format')\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Specify your file paths\n",
    "    input_file = '/kaggle/input/wgis-governance-1996-2023/Governance wgidataset with variable names.xlsx'\n",
    "    output_file = \"governance_data_filtered.csv\"\n",
    "    \n",
    "    # Define the countries to filter\n",
    "    selected_countries = [\n",
    "        'Argentina', 'Australia', 'Austria', 'Belgium', 'Brazil', 'Bulgaria', \n",
    "        'Canada', 'Chile', 'China', 'Colombia', 'Costa Rica', 'Croatia', \n",
    "        'Cyprus', 'Czech Republic', 'Denmark', 'Estonia', 'Finland', 'France', \n",
    "        'Germany', 'Greece', 'Hungary', 'Iceland', 'India', 'Indonesia', \n",
    "        'Ireland', 'Israel', 'Italy', 'Japan', 'Korea, Rep.', 'Latvia', \n",
    "        'Lithuania', 'Luxembourg', 'Malta', 'Mexico', 'Netherlands', \n",
    "        'New Zealand', 'Norway', 'Peru', 'Poland', 'Portugal', 'Romania', \n",
    "        'Russian Federation', 'Saudi Arabia', 'Slovak Republic', 'Slovenia', \n",
    "        'South Africa', 'Spain', 'Sweden', 'Switzerland', 'Türkiye', \n",
    "        'United Kingdom', 'United States'\n",
    "    ]\n",
    "    \n",
    "    # Define year range\n",
    "    start_year = 1998\n",
    "    end_year = 2018\n",
    "    \n",
    "    try:\n",
    "        # Transform the data\n",
    "        transformed_df = transform_governance_data(input_file)\n",
    "        \n",
    "        # Apply filters\n",
    "        print(f\"\\n\" + \"=\"*60)\n",
    "        print(\"APPLYING FILTERS\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Filtering for {len(selected_countries)} countries from {start_year} to {end_year}\")\n",
    "        \n",
    "        # Filter by countries and year range\n",
    "        filtered_df = transformed_df[\n",
    "            (transformed_df['countryname'].isin(selected_countries)) &\n",
    "            (transformed_df['year'] >= start_year) &\n",
    "            (transformed_df['year'] <= end_year)\n",
    "        ].copy()\n",
    "        \n",
    "        # Check for missing 1999 data and interpolate\n",
    "        print(f\"\\n\" + \"=\"*60)\n",
    "        print(\"HANDLING MISSING 1999 DATA\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Check if 1999 data is missing\n",
    "        missing_1999 = filtered_df[filtered_df['year'] == 1999]\n",
    "        print(f\"Existing 1999 records: {len(missing_1999)}\")\n",
    "        \n",
    "        if len(missing_1999) == 0:\n",
    "            print(\"No 1999 data found. Creating interpolated values...\")\n",
    "            filtered_df = interpolate_missing_1999(filtered_df, selected_countries)\n",
    "        else:\n",
    "            print(\"Some 1999 data exists. Checking for missing countries...\")\n",
    "            countries_with_1999 = set(missing_1999['countryname'].unique())\n",
    "            countries_without_1999 = set(selected_countries) - countries_with_1999\n",
    "            \n",
    "            if countries_without_1999:\n",
    "                print(f\"Countries missing 1999 data: {len(countries_without_1999)}\")\n",
    "                print(f\"Missing: {sorted(list(countries_without_1999))}\")\n",
    "                filtered_df = interpolate_missing_1999(filtered_df, list(countries_without_1999))\n",
    "            else:\n",
    "                print(\"All countries have 1999 data.\")\n",
    "        \n",
    "        print(f\"Filtered dataset shape: {filtered_df.shape}\")\n",
    "        \n",
    "        # Check which countries from our list are actually in the data\n",
    "        available_countries = set(filtered_df['countryname'].unique())\n",
    "        requested_countries = set(selected_countries)\n",
    "        found_countries = available_countries.intersection(requested_countries)\n",
    "        missing_countries = requested_countries - available_countries\n",
    "        \n",
    "        print(f\"\\nCountries found in dataset: {len(found_countries)}\")\n",
    "        print(f\"Countries not found in dataset: {len(missing_countries)}\")\n",
    "        \n",
    "        if missing_countries:\n",
    "            print(f\"Missing countries: {sorted(list(missing_countries))}\")\n",
    "        \n",
    "        # Save filtered data\n",
    "        filtered_df.to_csv(output_file, index=False)\n",
    "        print(f\"\\nFiltered data saved to: {output_file}\")\n",
    "        \n",
    "        # Display sample of the filtered data\n",
    "        display_sample_data(filtered_df)\n",
    "        \n",
    "        # Additional analysis for filtered data\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"FILTERED DATA ANALYSIS\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Year range in filtered data\n",
    "        actual_year_range = f\"{filtered_df['year'].min()} - {filtered_df['year'].max()}\"\n",
    "        print(f\"Actual year range in filtered data: {actual_year_range}\")\n",
    "        \n",
    "        # Number of observations per country\n",
    "        country_obs = filtered_df['countryname'].value_counts().sort_index()\n",
    "        print(f\"\\nObservations per country ({start_year}-{end_year}):\")\n",
    "        for country, count in country_obs.items():\n",
    "            print(f\"  {country}: {count} observations\")\n",
    "        \n",
    "        # Check for complete records (all 6 indicators)\n",
    "        complete_filtered = filtered_df.dropna()\n",
    "        print(f\"\\nComplete records in filtered data: {len(complete_filtered)} out of {len(filtered_df)}\")\n",
    "        \n",
    "        # Missing data by indicator in filtered dataset\n",
    "        print(f\"\\nMissing data by indicator (filtered dataset):\")\n",
    "        indicator_cols = [col for col in filtered_df.columns if col not in ['countryname', 'year']]\n",
    "        for col in indicator_cols:\n",
    "            missing_count = filtered_df[col].isna().sum()\n",
    "            missing_pct = (missing_count / len(filtered_df)) * 100\n",
    "            print(f\"  {col}: {missing_count} missing ({missing_pct:.1f}%)\")\n",
    "        \n",
    "        # Summary statistics for filtered data\n",
    "        print(f\"\\nGovernance indicators summary (filtered data):\")\n",
    "        print(filtered_df[indicator_cols].describe().round(3))\n",
    "        \n",
    "        # Optional: Save complete records only\n",
    "        complete_output_file = \"governance_data_filtered_complete.csv\"\n",
    "        if len(complete_filtered) > 0:\n",
    "            complete_filtered.to_csv(complete_output_file, index=False)\n",
    "            print(f\"\\nComplete records only saved to: {complete_output_file}\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Could not find the file '{input_file}'\")\n",
    "        print(\"Please make sure the file exists in the current directory.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "\n",
    "# Additional utility functions\n",
    "\n",
    "def filter_by_year_range(df, start_year, end_year):\n",
    "    \"\"\"\n",
    "    Filter the transformed dataset by year range.\n",
    "    \"\"\"\n",
    "    filtered_df = df[(df['year'] >= start_year) & (df['year'] <= end_year)]\n",
    "    print(f\"Filtered data ({start_year}-{end_year}): {len(filtered_df)} rows\")\n",
    "    return filtered_df\n",
    "\n",
    "def filter_by_countries(df, country_list):\n",
    "    \"\"\"\n",
    "    Filter the transformed dataset by specific countries.\n",
    "    \"\"\"\n",
    "    filtered_df = df[df['countryname'].isin(country_list)]\n",
    "    print(f\"Filtered data for {len(country_list)} countries: {len(filtered_df)} rows\")\n",
    "    return filtered_df\n",
    "\n",
    "def export_complete_records_only(df, output_file):\n",
    "    \"\"\"\n",
    "    Export only records that have all 6 governance indicators.\n",
    "    \"\"\"\n",
    "    complete_df = df.dropna()\n",
    "    complete_df.to_csv(output_file, index=False)\n",
    "    print(f\"Complete records only ({len(complete_df)} rows) saved to: {output_file}\")\n",
    "    return complete_df\n",
    "\n",
    "# Example usage of utility functions:\n",
    "\"\"\"\n",
    "# After running the main transformation:\n",
    "# Filter by year range\n",
    "recent_data = filter_by_year_range(transformed_df, 2010, 2020)\n",
    "\n",
    "# Filter by specific countries\n",
    "countries_of_interest = ['United States', 'China', 'Germany', 'Brazil', 'India']\n",
    "country_subset = filter_by_countries(transformed_df, countries_of_interest)\n",
    "\n",
    "# Export only complete records\n",
    "complete_data = export_complete_records_only(transformed_df, \"governance_complete_records.csv\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2444ccce",
   "metadata": {
    "papermill": {
     "duration": 0.005709,
     "end_time": "2025-05-23T16:16:27.221907",
     "exception": false,
     "start_time": "2025-05-23T16:16:27.216198",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Predicting and Filling the missing 1999 and 2001 data for every indicators using linear prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00519a45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T16:16:27.235724Z",
     "iopub.status.busy": "2025-05-23T16:16:27.235409Z",
     "iopub.status.idle": "2025-05-23T16:16:38.382451Z",
     "shell.execute_reply": "2025-05-23T16:16:38.381273Z"
    },
    "papermill": {
     "duration": 11.156629,
     "end_time": "2025-05-23T16:16:38.384457",
     "exception": false,
     "start_time": "2025-05-23T16:16:27.227828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the Excel file...\n",
      "Original dataset shape: (32100, 9)\n",
      "Columns: ['countryname', 'year', 'indicator', 'estimate', 'stddev', 'nsource', 'pctrank', 'pctranklower', 'pctrankupper']\n",
      "Unique indicators found: ['cc' 'ge' 'pv' 'rl' 'rq' 'va']\n",
      "Filtering out rows with missing estimates...\n",
      "Dataset shape after removing missing estimates: (30974, 9)\n",
      "Pivoting data - converting indicators to columns...\n",
      "Final dataset shape: (5246, 8)\n",
      "Final columns: ['countryname', 'year', 'cc', 'ge', 'pv', 'rl', 'rq', 'va']\n",
      "\n",
      "==================================================\n",
      "TRANSFORMATION SUMMARY\n",
      "==================================================\n",
      "Total country-year observations: 5246\n",
      "Complete records (all 6 indicators): 5045\n",
      "\n",
      "Missing data by indicator:\n",
      "  cc: 103 missing values\n",
      "  ge: 127 missing values\n",
      "  pv: 68 missing values\n",
      "  rl: 13 missing values\n",
      "  rq: 125 missing values\n",
      "  va: 66 missing values\n",
      "\n",
      "First 5 rows of transformed data:\n",
      "   countryname  year        cc        ge        pv        rl        rq  \\\n",
      "0  Afghanistan  1996 -1.291705 -2.175167 -2.417310 -1.788075 -2.090330   \n",
      "1  Afghanistan  1998 -1.176012 -2.102292 -2.427355 -1.734887 -2.062872   \n",
      "2  Afghanistan  2000 -1.271724 -2.173946 -2.438969 -1.780661 -2.080253   \n",
      "3  Afghanistan  2002 -1.251137 -1.587687 -2.035034 -1.673473 -1.811546   \n",
      "4  Afghanistan  2003 -1.344180 -1.175768 -2.198372 -1.558294 -1.463108   \n",
      "\n",
      "         va  \n",
      "0 -1.908540  \n",
      "1 -2.039301  \n",
      "2 -2.031417  \n",
      "3 -1.433421  \n",
      "4 -1.177571  \n",
      "\n",
      "============================================================\n",
      "APPLYING FILTERS\n",
      "============================================================\n",
      "Filtering for 52 countries from 1998 to 2018\n",
      "Filtered dataset shape: (988, 8)\n",
      "\n",
      "Countries found in dataset: 52\n",
      "Countries not found in dataset: 0\n",
      "\n",
      "============================================================\n",
      "PREDICTION QUALITY ANALYSIS\n",
      "============================================================\n",
      "\n",
      "Testing predictions for Italy:\n",
      "  cc (2000): Actual=0.699, Predicted=0.548, Error=21.6%\n",
      "  ge (2000): Actual=0.723, Predicted=0.684, Error=5.3%\n",
      "  pv (2000): Actual=0.917, Predicted=1.134, Error=23.7%\n",
      "  rl (2000): Actual=0.838, Predicted=0.691, Error=17.5%\n",
      "  rq (2000): Actual=0.792, Predicted=0.699, Error=11.7%\n",
      "  va (2000): Actual=1.041, Predicted=1.065, Error=2.3%\n",
      "  cc (2002): Actual=0.523, Predicted=0.459, Error=12.4%\n",
      "  ge (2002): Actual=0.753, Predicted=0.823, Error=9.3%\n",
      "  pv (2002): Actual=0.838, Predicted=0.443, Error=47.2%\n",
      "  rl (2002): Actual=0.740, Predicted=0.655, Error=11.5%\n",
      "  rq (2002): Actual=0.904, Predicted=1.054, Error=16.5%\n",
      "  va (2002): Actual=1.039, Predicted=0.985, Error=5.1%\n",
      "\n",
      "Testing predictions for Slovak Republic:\n",
      "  cc (2000): Actual=0.223, Predicted=0.243, Error=9.0%\n",
      "  ge (2000): Actual=0.673, Predicted=0.597, Error=11.3%\n",
      "  pv (2000): Actual=0.664, Predicted=0.989, Error=49.0%\n",
      "  rl (2000): Actual=0.300, Predicted=0.257, Error=14.3%\n",
      "  rq (2000): Actual=0.578, Predicted=0.480, Error=17.0%\n",
      "  va (2000): Actual=0.849, Predicted=0.829, Error=2.3%\n",
      "  cc (2002): Actual=-0.051, Predicted=0.272, Error=638.1%\n",
      "  ge (2002): Actual=0.541, Predicted=0.715, Error=32.2%\n",
      "  pv (2002): Actual=0.940, Predicted=0.918, Error=2.3%\n",
      "  rl (2002): Actual=0.286, Predicted=0.358, Error=25.2%\n",
      "  rq (2002): Actual=0.904, Predicted=0.929, Error=2.7%\n",
      "  va (2002): Actual=0.976, Predicted=0.864, Error=11.5%\n",
      "\n",
      "Testing predictions for Indonesia:\n",
      "  cc (2000): Actual=-0.909, Predicted=-1.093, Error=20.3%\n",
      "  ge (2000): Actual=-0.366, Predicted=-0.616, Error=68.4%\n",
      "  pv (2000): Actual=-1.995, Predicted=-2.088, Error=4.7%\n",
      "  rl (2000): Actual=-0.697, Predicted=-0.886, Error=27.2%\n",
      "  rq (2000): Actual=-0.260, Predicted=-0.704, Error=170.2%\n",
      "  va (2000): Actual=-0.270, Predicted=-0.640, Error=136.7%\n",
      "  cc (2002): Actual=-1.137, Predicted=-0.980, Error=13.8%\n",
      "  ge (2002): Actual=-0.551, Predicted=-0.512, Error=6.9%\n",
      "  pv (2002): Actual=-1.583, Predicted=-1.908, Error=20.5%\n",
      "  rl (2002): Actual=-0.910, Predicted=-0.765, Error=16.0%\n",
      "  rq (2002): Actual=-0.742, Predicted=-0.531, Error=28.4%\n",
      "  va (2002): Actual=-0.272, Predicted=-0.393, Error=44.7%\n",
      "\n",
      "Testing predictions for Finland:\n",
      "  cc (2000): Actual=2.368, Predicted=2.368, Error=0.0%\n",
      "  ge (2000): Actual=2.030, Predicted=1.947, Error=4.1%\n",
      "  pv (2000): Actual=1.720, Predicted=1.594, Error=7.3%\n",
      "  rl (2000): Actual=1.953, Predicted=1.911, Error=2.2%\n",
      "  rq (2000): Actual=1.783, Predicted=1.717, Error=3.7%\n",
      "  va (2000): Actual=1.593, Predicted=1.473, Error=7.5%\n",
      "  cc (2002): Actual=2.369, Predicted=2.342, Error=1.1%\n",
      "  ge (2002): Actual=2.096, Predicted=2.196, Error=4.7%\n",
      "  pv (2002): Actual=1.753, Predicted=1.614, Error=7.9%\n",
      "  rl (2002): Actual=1.904, Predicted=1.934, Error=1.6%\n",
      "  rq (2002): Actual=1.816, Predicted=1.727, Error=4.9%\n",
      "  va (2002): Actual=1.553, Predicted=1.570, Error=1.1%\n",
      "\n",
      "Testing predictions for Czech Republic:\n",
      "  cc (2000): Actual=0.146, Predicted=0.533, Error=264.7%\n",
      "  ge (2000): Actual=0.587, Predicted=0.803, Error=36.8%\n",
      "  pv (2000): Actual=0.333, Predicted=0.951, Error=185.9%\n",
      "  rl (2000): Actual=0.607, Predicted=0.810, Error=33.5%\n",
      "  rq (2000): Actual=0.744, Predicted=1.064, Error=43.1%\n",
      "  va (2000): Actual=0.763, Predicted=0.968, Error=27.0%\n",
      "  cc (2002): Actual=0.358, Predicted=0.485, Error=35.5%\n",
      "  ge (2002): Actual=0.922, Predicted=0.764, Error=17.1%\n",
      "  pv (2002): Actual=1.044, Predicted=0.863, Error=17.4%\n",
      "  rl (2002): Actual=0.860, Predicted=0.803, Error=6.6%\n",
      "  rq (2002): Actual=1.113, Predicted=1.016, Error=8.7%\n",
      "  va (2002): Actual=1.016, Predicted=1.014, Error=0.2%\n",
      "\n",
      "Overall prediction accuracy: 62.0% (avg relative error: 38.0%)\n",
      "\n",
      "============================================================\n",
      "PREDICTING MISSING [1999, 2001] DATA\n",
      "============================================================\n",
      "\n",
      "1999 data status:\n",
      "  Countries with existing data: 0\n",
      "  Countries needing prediction: 52\n",
      "\n",
      "2001 data status:\n",
      "  Countries with existing data: 0\n",
      "  Countries needing prediction: 52\n",
      "\n",
      "Countries needing predictions: 52\n",
      "Predicting [1999, 2001] data for 52 countries using adaptive method...\n",
      "  Predicting 1999 data for Italy...\n",
      "    Italy (1999): Predicted 6/6 indicators\n",
      "  Predicting 2001 data for Italy...\n",
      "    Italy (2001): Predicted 6/6 indicators\n",
      "  Predicting 1999 data for Slovak Republic...\n",
      "    Slovak Republic (1999): Predicted 6/6 indicators\n",
      "  Predicting 2001 data for Slovak Republic...\n",
      "    Slovak Republic (2001): Predicted 6/6 indicators\n",
      "  Predicting 1999 data for Indonesia...\n",
      "    Indonesia (1999): Predicted 6/6 indicators\n",
      "  Predicting 2001 data for Indonesia...\n",
      "    Indonesia (2001): Predicted 6/6 indicators\n",
      "  Predicting 1999 data for Finland...\n",
      "    Finland (1999): Predicted 6/6 indicators\n",
      "  Predicting 2001 data for Finland...\n",
      "    Finland (2001): Predicted 6/6 indicators\n",
      "  Predicting 1999 data for Czech Republic...\n",
      "    Czech Republic (1999): Predicted 6/6 indicators\n",
      "  Predicting 2001 data for Czech Republic...\n",
      "    Czech Republic (2001): Predicted 6/6 indicators\n",
      "  Predicting 1999 data for United States...\n",
      "    United States (1999): Predicted 6/6 indicators\n",
      "  Predicting 2001 data for United States...\n",
      "    United States (2001): Predicted 6/6 indicators\n",
      "  Predicting 1999 data for Hungary...\n",
      "    Hungary (1999): Predicted 6/6 indicators\n",
      "  Predicting 2001 data for Hungary...\n",
      "    Hungary (2001): Predicted 6/6 indicators\n",
      "  Predicting 1999 data for Belgium...\n",
      "    Belgium (1999): Predicted 6/6 indicators\n",
      "  Predicting 2001 data for Belgium...\n",
      "    Belgium (2001): Predicted 6/6 indicators\n",
      "  Predicting 1999 data for Bulgaria...\n",
      "    Bulgaria (1999): Predicted 6/6 indicators\n",
      "  Predicting 2001 data for Bulgaria...\n",
      "    Bulgaria (2001): Predicted 6/6 indicators\n",
      "  Predicting 1999 data for Norway...\n",
      "    Norway (1999): Predicted 6/6 indicators\n",
      "  Predicting 2001 data for Norway...\n",
      "    Norway (2001): Predicted 6/6 indicators\n",
      "  Predicting 1999 data for China...\n",
      "    China (1999): Predicted 6/6 indicators\n",
      "  Predicting 2001 data for China...\n",
      "    China (2001): Predicted 6/6 indicators\n",
      "  Predicting 1999 data for India...\n",
      "    India (1999): Predicted 6/6 indicators\n",
      "  Predicting 2001 data for India...\n",
      "    India (2001): Predicted 6/6 indicators\n",
      "  Predicting 1999 data for Chile...\n",
      "    Chile (1999): Predicted 6/6 indicators\n",
      "  Predicting 2001 data for Chile...\n",
      "    Chile (2001): Predicted 6/6 indicators\n",
      "  Predicting 1999 data for Luxembourg...\n",
      "    Luxembourg (1999): Predicted 6/6 indicators\n",
      "  Predicting 2001 data for Luxembourg...\n",
      "    Luxembourg (2001): Predicted 6/6 indicators\n",
      "  Predicting 1999 data for Sweden...\n",
      "    Sweden (1999): Predicted 6/6 indicators\n",
      "  Predicting 2001 data for Sweden...\n",
      "    Sweden (2001): Predicted 6/6 indicators\n",
      "  Predicting 1999 data for Latvia...\n",
      "    Latvia (1999): Predicted 6/6 indicators\n",
      "  Predicting 2001 data for Latvia...\n",
      "    Latvia (2001): Predicted 6/6 indicators\n",
      "  Predicting 1999 data for Australia...\n",
      "    Australia (1999): Predicted 6/6 indicators\n",
      "  Predicting 2001 data for Australia...\n",
      "    Australia (2001): Predicted 6/6 indicators\n",
      "  Predicting 1999 data for Türkiye...\n",
      "    Türkiye (1999): Predicted 6/6 indicators\n",
      "  Predicting 2001 data for Türkiye...\n",
      "    Türkiye (2001): Predicted 6/6 indicators\n",
      "  Predicting 1999 data for Croatia...\n",
      "    Croatia (1999): Predicted 6/6 indicators\n",
      "  Predicting 2001 data for Croatia...\n",
      "    Croatia (2001): Predicted 6/6 indicators\n",
      "  Predicting 1999 data for Spain...\n",
      "    Spain (1999): Predicted 6/6 indicators\n",
      "  Predicting 2001 data for Spain...\n",
      "    Spain (2001): Predicted 6/6 indicators\n",
      "  Predicting 1999 data for Denmark...\n",
      "    Denmark (1999): Predicted 6/6 indicators\n",
      "  Predicting 2001 data for Denmark...\n",
      "    Denmark (2001): Predicted 6/6 indicators\n",
      "  Predicting 1999 data for Korea, Rep....\n",
      "    Korea, Rep. (1999): Predicted 6/6 indicators\n",
      "  Predicting 2001 data for Korea, Rep....\n",
      "    Korea, Rep. (2001): Predicted 6/6 indicators\n",
      "  Predicting 1999 data for Switzerland...\n",
      "    Switzerland (1999): Predicted 6/6 indicators\n",
      "  Predicting 2001 data for Switzerland...\n",
      "    Switzerland (2001): Predicted 6/6 indicators\n",
      "  Predicting 1999 data for Brazil...\n",
      "    Brazil (1999): Predicted 6/6 indicators\n",
      "  Predicting 2001 data for Brazil...\n",
      "    Brazil (2001): Predicted 6/6 indicators\n",
      "  Predicting 1999 data for Israel...\n",
      "    Israel (1999): Predicted 6/6 indicators\n",
      "  Predicting 2001 data for Israel...\n",
      "    Israel (2001): Predicted 6/6 indicators\n",
      "  Predicting 1999 data for Saudi Arabia...\n",
      "    Saudi Arabia (1999): Predicted 6/6 indicators\n",
      "  Predicting 2001 data for Saudi Arabia...\n",
      "    Saudi Arabia (2001): Predicted 6/6 indicators\n",
      "  Predicting 1999 data for Iceland...\n",
      "    Iceland (1999): Predicted 6/6 indicators\n",
      "  Predicting 2001 data for Iceland...\n",
      "    Iceland (2001): Predicted 6/6 indicators\n",
      "  Predicting 1999 data for Malta...\n",
      "    Malta (1999): Predicted 6/6 indicators\n",
      "  Predicting 2001 data for Malta...\n",
      "    Malta (2001): Predicted 6/6 indicators\n",
      "  Predicting 1999 data for Greece...\n",
      "    Greece (1999): Predicted 6/6 indicators\n",
      "  Predicting 2001 data for Greece...\n",
      "    Greece (2001): Predicted 6/6 indicators\n",
      "  Predicting 1999 data for Ireland...\n",
      "    Ireland (1999): Predicted 6/6 indicators\n",
      "  Predicting 2001 data for Ireland...\n",
      "    Ireland (2001): Predicted 6/6 indicators\n",
      "  Predicting 1999 data for Romania...\n",
      "    Romania (1999): Predicted 6/6 indicators\n",
      "  Predicting 2001 data for Romania...\n",
      "    Romania (2001): Predicted 6/6 indicators\n",
      "  Predicting 1999 data for Colombia...\n",
      "    Colombia (1999): Predicted 6/6 indicators\n",
      "  Predicting 2001 data for Colombia...\n",
      "    Colombia (2001): Predicted 6/6 indicators\n",
      "  Predicting 1999 data for Peru...\n",
      "    Peru (1999): Predicted 6/6 indicators\n",
      "  Predicting 2001 data for Peru...\n",
      "    Peru (2001): Predicted 6/6 indicators\n",
      "  Predicting 1999 data for South Africa...\n",
      "    South Africa (1999): Predicted 6/6 indicators\n",
      "  Predicting 2001 data for South Africa...\n",
      "    South Africa (2001): Predicted 6/6 indicators\n",
      "  Predicting 1999 data for Netherlands...\n",
      "    Netherlands (1999): Predicted 6/6 indicators\n",
      "  Predicting 2001 data for Netherlands...\n",
      "    Netherlands (2001): Predicted 6/6 indicators\n",
      "  Predicting 1999 data for Russian Federation...\n",
      "    Russian Federation (1999): Predicted 6/6 indicators\n",
      "  Predicting 2001 data for Russian Federation...\n",
      "    Russian Federation (2001): Predicted 6/6 indicators\n",
      "  Predicting 1999 data for United Kingdom...\n",
      "    United Kingdom (1999): Predicted 6/6 indicators\n",
      "  Predicting 2001 data for United Kingdom...\n",
      "    United Kingdom (2001): Predicted 6/6 indicators\n",
      "  Predicting 1999 data for Germany...\n",
      "    Germany (1999): Predicted 6/6 indicators\n",
      "  Predicting 2001 data for Germany...\n",
      "    Germany (2001): Predicted 6/6 indicators\n",
      "  Predicting 1999 data for Canada...\n",
      "    Canada (1999): Predicted 6/6 indicators\n",
      "  Predicting 2001 data for Canada...\n",
      "    Canada (2001): Predicted 6/6 indicators\n",
      "  Predicting 1999 data for Slovenia...\n",
      "    Slovenia (1999): Predicted 6/6 indicators\n",
      "  Predicting 2001 data for Slovenia...\n",
      "    Slovenia (2001): Predicted 6/6 indicators\n",
      "  Predicting 1999 data for Lithuania...\n",
      "    Lithuania (1999): Predicted 6/6 indicators\n",
      "  Predicting 2001 data for Lithuania...\n",
      "    Lithuania (2001): Predicted 6/6 indicators\n",
      "  Predicting 1999 data for Poland...\n",
      "    Poland (1999): Predicted 6/6 indicators\n",
      "  Predicting 2001 data for Poland...\n",
      "    Poland (2001): Predicted 6/6 indicators\n",
      "  Predicting 1999 data for Austria...\n",
      "    Austria (1999): Predicted 6/6 indicators\n",
      "  Predicting 2001 data for Austria...\n",
      "    Austria (2001): Predicted 6/6 indicators\n",
      "  Predicting 1999 data for Costa Rica...\n",
      "    Costa Rica (1999): Predicted 6/6 indicators\n",
      "  Predicting 2001 data for Costa Rica...\n",
      "    Costa Rica (2001): Predicted 6/6 indicators\n",
      "  Predicting 1999 data for Mexico...\n",
      "    Mexico (1999): Predicted 6/6 indicators\n",
      "  Predicting 2001 data for Mexico...\n",
      "    Mexico (2001): Predicted 6/6 indicators\n",
      "  Predicting 1999 data for Portugal...\n",
      "    Portugal (1999): Predicted 6/6 indicators\n",
      "  Predicting 2001 data for Portugal...\n",
      "    Portugal (2001): Predicted 6/6 indicators\n",
      "  Predicting 1999 data for Japan...\n",
      "    Japan (1999): Predicted 6/6 indicators\n",
      "  Predicting 2001 data for Japan...\n",
      "    Japan (2001): Predicted 6/6 indicators\n",
      "  Predicting 1999 data for New Zealand...\n",
      "    New Zealand (1999): Predicted 6/6 indicators\n",
      "  Predicting 2001 data for New Zealand...\n",
      "    New Zealand (2001): Predicted 6/6 indicators\n",
      "  Predicting 1999 data for Cyprus...\n",
      "    Cyprus (1999): Predicted 6/6 indicators\n",
      "  Predicting 2001 data for Cyprus...\n",
      "    Cyprus (2001): Predicted 6/6 indicators\n",
      "  Predicting 1999 data for France...\n",
      "    France (1999): Predicted 6/6 indicators\n",
      "  Predicting 2001 data for France...\n",
      "    France (2001): Predicted 6/6 indicators\n",
      "  Predicting 1999 data for Estonia...\n",
      "    Estonia (1999): Predicted 6/6 indicators\n",
      "  Predicting 2001 data for Estonia...\n",
      "    Estonia (2001): Predicted 6/6 indicators\n",
      "  Predicting 1999 data for Argentina...\n",
      "    Argentina (1999): Predicted 6/6 indicators\n",
      "  Predicting 2001 data for Argentina...\n",
      "    Argentina (2001): Predicted 6/6 indicators\n",
      "\n",
      "Added 104 predicted records\n",
      "\n",
      "Filtered data with predictions saved to: governance_data_filtered_with_predictions.csv\n",
      "\n",
      "Sample of transformed data (10 rows):\n",
      "----------------------------------------------------------------------------------------------------\n",
      "  countryname  year     cc     ge     pv     rl     rq    va\n",
      "0   Argentina  1998 -0.203  0.329 -0.135 -0.039  0.521 0.309\n",
      "1   Argentina  1999 -0.222  0.147 -0.306 -0.241  0.180 0.326\n",
      "2   Argentina  2000 -0.172 -0.028  0.096 -0.214  0.182 0.418\n",
      "3   Argentina  2001 -0.303  0.035 -0.259 -0.425 -0.183 0.441\n",
      "4   Argentina  2002 -0.417 -0.228 -0.777 -0.761 -0.881 0.260\n",
      "5   Argentina  2003 -0.480 -0.034 -0.360 -0.777 -0.691 0.349\n",
      "6   Argentina  2004 -0.414  0.015 -0.611 -0.767 -0.698 0.362\n",
      "7   Argentina  2005 -0.378 -0.098 -0.042 -0.558 -0.525 0.269\n",
      "8   Argentina  2006 -0.331 -0.034  0.002 -0.577 -0.615 0.403\n",
      "9   Argentina  2007 -0.372 -0.013  0.098 -0.601 -0.636 0.449\n",
      "\n",
      "============================================================\n",
      "FINAL DATA ANALYSIS\n",
      "============================================================\n",
      "Actual year range in filtered data: 1998 - 2018\n",
      "\n",
      "Observations per country (1998-2018):\n",
      "  Argentina: 21 observations (expected: 21)\n",
      "  Australia: 21 observations (expected: 21)\n",
      "  Austria: 21 observations (expected: 21)\n",
      "  Belgium: 21 observations (expected: 21)\n",
      "  Brazil: 21 observations (expected: 21)\n",
      "  Bulgaria: 21 observations (expected: 21)\n",
      "  Canada: 21 observations (expected: 21)\n",
      "  Chile: 21 observations (expected: 21)\n",
      "  China: 21 observations (expected: 21)\n",
      "  Colombia: 21 observations (expected: 21)\n",
      "  Costa Rica: 21 observations (expected: 21)\n",
      "  Croatia: 21 observations (expected: 21)\n",
      "  Cyprus: 21 observations (expected: 21)\n",
      "  Czech Republic: 21 observations (expected: 21)\n",
      "  Denmark: 21 observations (expected: 21)\n",
      "  Estonia: 21 observations (expected: 21)\n",
      "  Finland: 21 observations (expected: 21)\n",
      "  France: 21 observations (expected: 21)\n",
      "  Germany: 21 observations (expected: 21)\n",
      "  Greece: 21 observations (expected: 21)\n",
      "  Hungary: 21 observations (expected: 21)\n",
      "  Iceland: 21 observations (expected: 21)\n",
      "  India: 21 observations (expected: 21)\n",
      "  Indonesia: 21 observations (expected: 21)\n",
      "  Ireland: 21 observations (expected: 21)\n",
      "  Israel: 21 observations (expected: 21)\n",
      "  Italy: 21 observations (expected: 21)\n",
      "  Japan: 21 observations (expected: 21)\n",
      "  Korea, Rep.: 21 observations (expected: 21)\n",
      "  Latvia: 21 observations (expected: 21)\n",
      "  Lithuania: 21 observations (expected: 21)\n",
      "  Luxembourg: 21 observations (expected: 21)\n",
      "  Malta: 21 observations (expected: 21)\n",
      "  Mexico: 21 observations (expected: 21)\n",
      "  Netherlands: 21 observations (expected: 21)\n",
      "  New Zealand: 21 observations (expected: 21)\n",
      "  Norway: 21 observations (expected: 21)\n",
      "  Peru: 21 observations (expected: 21)\n",
      "  Poland: 21 observations (expected: 21)\n",
      "  Portugal: 21 observations (expected: 21)\n",
      "  Romania: 21 observations (expected: 21)\n",
      "  Russian Federation: 21 observations (expected: 21)\n",
      "  Saudi Arabia: 21 observations (expected: 21)\n",
      "  Slovak Republic: 21 observations (expected: 21)\n",
      "  Slovenia: 21 observations (expected: 21)\n",
      "  South Africa: 21 observations (expected: 21)\n",
      "  Spain: 21 observations (expected: 21)\n",
      "  Sweden: 21 observations (expected: 21)\n",
      "  Switzerland: 21 observations (expected: 21)\n",
      "  Türkiye: 21 observations (expected: 21)\n",
      "  United Kingdom: 21 observations (expected: 21)\n",
      "  United States: 21 observations (expected: 21)\n",
      "\n",
      "Complete records in filtered data: 1092 out of 1092\n",
      "\n",
      "Missing data by indicator (after predictions):\n",
      "  cc: 0 missing (0.0%)\n",
      "  ge: 0 missing (0.0%)\n",
      "  pv: 0 missing (0.0%)\n",
      "  rl: 0 missing (0.0%)\n",
      "  rq: 0 missing (0.0%)\n",
      "  va: 0 missing (0.0%)\n",
      "\n",
      "Governance indicators summary (after predictions):\n",
      "             cc        ge        pv        rl        rq        va\n",
      "count  1092.000  1092.000  1092.000  1092.000  1092.000  1092.000\n",
      "mean      0.820     0.910     0.445     0.841     0.930     0.836\n",
      "std       0.953     0.773     0.827     0.856     0.681     0.746\n",
      "min      -1.160    -0.757    -2.376    -1.084    -1.066    -1.907\n",
      "25%       0.002     0.224     0.003     0.097     0.451     0.530\n",
      "50%       0.776     0.971     0.635     0.967     1.049     1.032\n",
      "75%       1.746     1.631     1.053     1.661     1.511     1.370\n",
      "max       2.459     2.347     1.759     2.125     2.082     1.801\n",
      "\n",
      "Complete records only saved to: governance_data_complete_with_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def predict_missing_data_advanced(df, countries_to_predict, target_years=[1999, 2001], method='polynomial'):\n",
    "    \"\"\"\n",
    "    Predict missing data for specified countries and years using advanced methods.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The filtered dataset\n",
    "    countries_to_predict (list): List of countries missing target year data\n",
    "    target_years (list): Years to predict (default: [1999, 2001])\n",
    "    method (str): Prediction method ('linear', 'polynomial', 'trend', or 'adaptive')\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: Dataset with predicted data\n",
    "    \"\"\"\n",
    "    print(f\"Predicting {target_years} data for {len(countries_to_predict)} countries using {method} method...\")\n",
    "    \n",
    "    # Get indicator columns (excluding countryname and year)\n",
    "    indicator_cols = [col for col in df.columns if col not in ['countryname', 'year']]\n",
    "    \n",
    "    # Create list to store new predicted rows\n",
    "    new_predicted_rows = []\n",
    "    \n",
    "    for country in countries_to_predict:\n",
    "        country_data = df[df['countryname'] == country].copy()\n",
    "        \n",
    "        if len(country_data) == 0:\n",
    "            print(f\"  Warning: No data found for {country}\")\n",
    "            continue\n",
    "        \n",
    "        # Sort by year for proper time series analysis\n",
    "        country_data = country_data.sort_values('year')\n",
    "        \n",
    "        for target_year in target_years:\n",
    "            # Skip if data already exists for this year\n",
    "            if target_year in country_data['year'].values:\n",
    "                continue\n",
    "                \n",
    "            print(f\"  Predicting {target_year} data for {country}...\")\n",
    "            \n",
    "            # Create new predicted row\n",
    "            new_row = {'countryname': country, 'year': target_year}\n",
    "            predicted_indicators = 0\n",
    "            \n",
    "            for indicator in indicator_cols:\n",
    "                predicted_value = predict_indicator_value(\n",
    "                    country_data, indicator, target_year, method\n",
    "                )\n",
    "                \n",
    "                if predicted_value is not None:\n",
    "                    new_row[indicator] = predicted_value\n",
    "                    predicted_indicators += 1\n",
    "                else:\n",
    "                    new_row[indicator] = np.nan\n",
    "            \n",
    "            if predicted_indicators > 0:\n",
    "                new_predicted_rows.append(new_row)\n",
    "                print(f\"    {country} ({target_year}): Predicted {predicted_indicators}/{len(indicator_cols)} indicators\")\n",
    "            else:\n",
    "                print(f\"    {country} ({target_year}): Could not predict any indicators\")\n",
    "    \n",
    "    # Add new predicted rows to the dataframe\n",
    "    if new_predicted_rows:\n",
    "        new_predicted_df = pd.DataFrame(new_predicted_rows)\n",
    "        df_with_predictions = pd.concat([df, new_predicted_df], ignore_index=True)\n",
    "        df_with_predictions = df_with_predictions.sort_values(['countryname', 'year']).reset_index(drop=True)\n",
    "        \n",
    "        print(f\"\\nAdded {len(new_predicted_rows)} predicted records\")\n",
    "        return df_with_predictions\n",
    "    else:\n",
    "        print(\"\\nNo predicted records were added\")\n",
    "        return df\n",
    "\n",
    "def predict_indicator_value(country_data, indicator, target_year, method='polynomial'):\n",
    "    \"\"\"\n",
    "    Predict a single indicator value for a target year using various methods.\n",
    "    \"\"\"\n",
    "    # Get available data for this indicator\n",
    "    available_data = country_data.dropna(subset=[indicator]).copy()\n",
    "    \n",
    "    if len(available_data) < 2:\n",
    "        # Fall back to nearest neighbor if insufficient data\n",
    "        return find_nearest_value(country_data, indicator, target_year)\n",
    "    \n",
    "    X = available_data['year'].values.reshape(-1, 1)\n",
    "    y = available_data[indicator].values\n",
    "    \n",
    "    try:\n",
    "        if method == 'linear':\n",
    "            return predict_linear(X, y, target_year)\n",
    "        elif method == 'polynomial':\n",
    "            return predict_polynomial(X, y, target_year)\n",
    "        elif method == 'trend':\n",
    "            return predict_trend_based(X, y, target_year)\n",
    "        elif method == 'adaptive':\n",
    "            return predict_adaptive(X, y, target_year)\n",
    "        else:\n",
    "            return predict_polynomial(X, y, target_year)  # Default to polynomial\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"    Warning: Prediction failed for {indicator}, using nearest value\")\n",
    "        return find_nearest_value(country_data, indicator, target_year)\n",
    "\n",
    "def predict_linear(X, y, target_year):\n",
    "    \"\"\"Linear regression prediction.\"\"\"\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    return model.predict([[target_year]])[0]\n",
    "\n",
    "def predict_polynomial(X, y, target_year, degree=2):\n",
    "    \"\"\"Polynomial regression prediction.\"\"\"\n",
    "    # Use degree 2 for small datasets, degree 3 for larger ones\n",
    "    if len(X) < 4:\n",
    "        degree = min(degree, len(X) - 1)\n",
    "    \n",
    "    poly_features = PolynomialFeatures(degree=degree)\n",
    "    X_poly = poly_features.fit_transform(X)\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(X_poly, y)\n",
    "    \n",
    "    target_poly = poly_features.transform([[target_year]])\n",
    "    return model.predict(target_poly)[0]\n",
    "\n",
    "def predict_trend_based(X, y, target_year):\n",
    "    \"\"\"Trend-based prediction using growth rates.\"\"\"\n",
    "    if len(X) < 3:\n",
    "        return predict_linear(X, y, target_year)\n",
    "    \n",
    "    # Calculate year-over-year growth rates\n",
    "    growth_rates = []\n",
    "    for i in range(1, len(y)):\n",
    "        if y[i-1] != 0:\n",
    "            growth_rate = (y[i] - y[i-1]) / abs(y[i-1])\n",
    "            growth_rates.append(growth_rate)\n",
    "    \n",
    "    if not growth_rates:\n",
    "        return predict_linear(X, y, target_year)\n",
    "    \n",
    "    # Use median growth rate to reduce impact of outliers\n",
    "    median_growth = np.median(growth_rates)\n",
    "    \n",
    "    # Find closest available year to target\n",
    "    year_diffs = np.abs(X.flatten() - target_year)\n",
    "    closest_idx = np.argmin(year_diffs)\n",
    "    closest_year = X[closest_idx][0]\n",
    "    closest_value = y[closest_idx]\n",
    "    \n",
    "    # Apply growth rate\n",
    "    years_diff = target_year - closest_year\n",
    "    predicted_value = closest_value * (1 + median_growth) ** years_diff\n",
    "    \n",
    "    return predicted_value\n",
    "\n",
    "def predict_adaptive(X, y, target_year):\n",
    "    \"\"\"Adaptive prediction that chooses best method based on data characteristics.\"\"\"\n",
    "    if len(X) < 3:\n",
    "        return predict_linear(X, y, target_year)\n",
    "    \n",
    "    # Try different methods and choose based on cross-validation-like approach\n",
    "    methods = {\n",
    "        'linear': predict_linear,\n",
    "        'polynomial': predict_polynomial,\n",
    "        'trend': predict_trend_based\n",
    "    }\n",
    "    \n",
    "    best_method = 'linear'\n",
    "    best_score = float('inf')\n",
    "    \n",
    "    # Simple validation: leave-one-out for last few points\n",
    "    if len(X) >= 4:\n",
    "        for method_name, method_func in methods.items():\n",
    "            try:\n",
    "                scores = []\n",
    "                # Test on last 2-3 points\n",
    "                test_points = min(3, len(X) - 2)\n",
    "                for i in range(test_points):\n",
    "                    test_idx = len(X) - 1 - i\n",
    "                    X_train = np.delete(X, test_idx, axis=0)\n",
    "                    y_train = np.delete(y, test_idx)\n",
    "                    actual = y[test_idx]\n",
    "                    \n",
    "                    if method_name == 'trend':\n",
    "                        predicted = predict_trend_based(X_train, y_train, X[test_idx][0])\n",
    "                    elif method_name == 'polynomial':\n",
    "                        predicted = predict_polynomial(X_train, y_train, X[test_idx][0])\n",
    "                    else:\n",
    "                        predicted = predict_linear(X_train, y_train, X[test_idx][0])\n",
    "                    \n",
    "                    if not np.isnan(predicted) and not np.isinf(predicted):\n",
    "                        scores.append(abs(actual - predicted))\n",
    "                \n",
    "                if scores:\n",
    "                    avg_score = np.mean(scores)\n",
    "                    if avg_score < best_score:\n",
    "                        best_score = avg_score\n",
    "                        best_method = method_name\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    # Use best method for final prediction\n",
    "    if best_method == 'trend':\n",
    "        return predict_trend_based(X, y, target_year)\n",
    "    elif best_method == 'polynomial':\n",
    "        return predict_polynomial(X, y, target_year)\n",
    "    else:\n",
    "        return predict_linear(X, y, target_year)\n",
    "\n",
    "def interpolate_missing_1999(df, countries_to_interpolate):\n",
    "    \"\"\"\n",
    "    Original interpolation function (kept for backward compatibility).\n",
    "    \"\"\"\n",
    "    print(f\"Interpolating 1999 data for {len(countries_to_interpolate)} countries...\")\n",
    "    \n",
    "    # Get indicator columns (excluding countryname and year)\n",
    "    indicator_cols = [col for col in df.columns if col not in ['countryname', 'year']]\n",
    "    \n",
    "    # Create list to store new 1999 rows\n",
    "    new_1999_rows = []\n",
    "    \n",
    "    for country in countries_to_interpolate:\n",
    "        country_data = df[df['countryname'] == country].copy()\n",
    "        \n",
    "        if len(country_data) == 0:\n",
    "            print(f\"  Warning: No data found for {country}\")\n",
    "            continue\n",
    "            \n",
    "        # Get 1998 and 2000 data for interpolation\n",
    "        data_1998 = country_data[country_data['year'] == 1998]\n",
    "        data_2000 = country_data[country_data['year'] == 2000]\n",
    "        \n",
    "        # Create new 1999 row\n",
    "        new_row = {'countryname': country, 'year': 1999}\n",
    "        \n",
    "        interpolated_indicators = 0\n",
    "        \n",
    "        for indicator in indicator_cols:\n",
    "            val_1998 = data_1998[indicator].iloc[0] if len(data_1998) > 0 and not pd.isna(data_1998[indicator].iloc[0]) else None\n",
    "            val_2000 = data_2000[indicator].iloc[0] if len(data_2000) > 0 and not pd.isna(data_2000[indicator].iloc[0]) else None\n",
    "            \n",
    "            if val_1998 is not None and val_2000 is not None:\n",
    "                # Linear interpolation: average of 1998 and 2000\n",
    "                interpolated_value = (val_1998 + val_2000) / 2\n",
    "                new_row[indicator] = interpolated_value\n",
    "                interpolated_indicators += 1\n",
    "            elif val_1998 is not None:\n",
    "                # Use 1998 value if 2000 is missing\n",
    "                new_row[indicator] = val_1998\n",
    "                interpolated_indicators += 1\n",
    "            elif val_2000 is not None:\n",
    "                # Use 2000 value if 1998 is missing\n",
    "                new_row[indicator] = val_2000\n",
    "                interpolated_indicators += 1\n",
    "            else:\n",
    "                # Both years missing, try to find nearest available data\n",
    "                nearest_value = find_nearest_value(country_data, indicator, 1999)\n",
    "                new_row[indicator] = nearest_value\n",
    "                if nearest_value is not None:\n",
    "                    interpolated_indicators += 1\n",
    "        \n",
    "        if interpolated_indicators > 0:\n",
    "            new_1999_rows.append(new_row)\n",
    "            print(f\"  {country}: Interpolated {interpolated_indicators}/{len(indicator_cols)} indicators\")\n",
    "        else:\n",
    "            print(f\"  {country}: Could not interpolate any indicators (insufficient data)\")\n",
    "    \n",
    "    # Add new 1999 rows to the dataframe\n",
    "    if new_1999_rows:\n",
    "        new_1999_df = pd.DataFrame(new_1999_rows)\n",
    "        df_with_1999 = pd.concat([df, new_1999_df], ignore_index=True)\n",
    "        df_with_1999 = df_with_1999.sort_values(['countryname', 'year']).reset_index(drop=True)\n",
    "        \n",
    "        print(f\"\\nAdded {len(new_1999_rows)} interpolated 1999 records\")\n",
    "        return df_with_1999\n",
    "    else:\n",
    "        print(\"\\nNo 1999 records were added\")\n",
    "        return df\n",
    "\n",
    "def find_nearest_value(country_data, indicator, target_year):\n",
    "    \"\"\"\n",
    "    Find the nearest available value for an indicator around the target year.\n",
    "    \"\"\"\n",
    "    # Get all available years for this country and indicator\n",
    "    available_data = country_data.dropna(subset=[indicator])\n",
    "    \n",
    "    if len(available_data) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Find the closest year\n",
    "    available_data['year_diff'] = abs(available_data['year'] - target_year)\n",
    "    closest_row = available_data.loc[available_data['year_diff'].idxmin()]\n",
    "    \n",
    "    return closest_row[indicator]\n",
    "\n",
    "def transform_governance_data(input_file, output_file=None):\n",
    "    \"\"\"\n",
    "    Transform governance dataset by pivoting indicators into separate columns.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read the Excel file\n",
    "    print(\"Reading the Excel file...\")\n",
    "    df = pd.read_excel(input_file, sheet_name=0)  # Read first sheet\n",
    "    \n",
    "    print(f\"Original dataset shape: {df.shape}\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "    \n",
    "    # Display unique indicators\n",
    "    unique_indicators = df['indicator'].unique()\n",
    "    print(f\"Unique indicators found: {unique_indicators}\")\n",
    "    \n",
    "    # Filter out rows with missing estimates (marked as \"..\" or actual NaN)\n",
    "    print(\"Filtering out rows with missing estimates...\")\n",
    "    df_clean = df[df['estimate'] != '..'].copy()\n",
    "    df_clean = df_clean.dropna(subset=['estimate'])\n",
    "    \n",
    "    print(f\"Dataset shape after removing missing estimates: {df_clean.shape}\")\n",
    "    \n",
    "    # Convert estimate to numeric if it's not already\n",
    "    df_clean['estimate'] = pd.to_numeric(df_clean['estimate'], errors='coerce')\n",
    "    \n",
    "    # Remove any rows where estimate conversion failed\n",
    "    df_clean = df_clean.dropna(subset=['estimate'])\n",
    "    \n",
    "    # Pivot the data: indicators become columns with their estimate values\n",
    "    print(\"Pivoting data - converting indicators to columns...\")\n",
    "    df_pivoted = df_clean.pivot_table(\n",
    "        index=['countryname', 'year'], \n",
    "        columns='indicator', \n",
    "        values='estimate',\n",
    "        aggfunc='first'  # In case of duplicates, take the first value\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Flatten column names (remove the multi-level index)\n",
    "    df_pivoted.columns.name = None\n",
    "    \n",
    "    # Reorder columns: countryname, year, then indicators in alphabetical order\n",
    "    indicator_columns = [col for col in df_pivoted.columns if col not in ['countryname', 'year']]\n",
    "    indicator_columns.sort()  # Sort indicators alphabetically\n",
    "    \n",
    "    final_columns = ['countryname', 'year'] + indicator_columns\n",
    "    df_final = df_pivoted[final_columns].copy()\n",
    "    \n",
    "    print(f\"Final dataset shape: {df_final.shape}\")\n",
    "    print(f\"Final columns: {list(df_final.columns)}\")\n",
    "    \n",
    "    # Display summary statistics\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"TRANSFORMATION SUMMARY\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Total country-year observations: {len(df_final)}\")\n",
    "    \n",
    "    # Check how many rows have all indicators\n",
    "    complete_rows = df_final.dropna()\n",
    "    print(f\"Complete records (all 6 indicators): {len(complete_rows)}\")\n",
    "    \n",
    "    # Show missing data by indicator\n",
    "    print(\"\\nMissing data by indicator:\")\n",
    "    for col in indicator_columns:\n",
    "        missing_count = df_final[col].isna().sum()\n",
    "        print(f\"  {col}: {missing_count} missing values\")\n",
    "    \n",
    "    # Display first few rows\n",
    "    print(f\"\\nFirst 5 rows of transformed data:\")\n",
    "    print(df_final.head())\n",
    "    \n",
    "    # Save to CSV if output file is specified\n",
    "    if output_file:\n",
    "        df_final.to_csv(output_file, index=False)\n",
    "        print(f\"\\nTransformed data saved to: {output_file}\")\n",
    "    \n",
    "    return df_final\n",
    "\n",
    "def display_sample_data(df, n_rows=10):\n",
    "    \"\"\"\n",
    "    Display sample data with better formatting.\n",
    "    \"\"\"\n",
    "    print(f\"\\nSample of transformed data ({n_rows} rows):\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    # Create a formatted display\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "    pd.set_option('display.float_format', '{:.3f}'.format)\n",
    "    \n",
    "    print(df.head(n_rows))\n",
    "    \n",
    "    # Reset display options\n",
    "    pd.reset_option('display.max_columns')\n",
    "    pd.reset_option('display.width')\n",
    "    pd.reset_option('display.float_format')\n",
    "\n",
    "def analyze_prediction_quality(df, countries_list, test_years=[2000, 2002], prediction_method='adaptive'):\n",
    "    \"\"\"\n",
    "    Analyze the quality of predictions by testing on known data.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"PREDICTION QUALITY ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    indicator_cols = [col for col in df.columns if col not in ['countryname', 'year']]\n",
    "    \n",
    "    total_predictions = 0\n",
    "    total_error = 0\n",
    "    method_errors = {}\n",
    "    \n",
    "    for country in countries_list[:5]:  # Test on subset of countries\n",
    "        country_data = df[df['countryname'] == country].copy()\n",
    "        \n",
    "        if len(country_data) < 5:  # Need sufficient data for testing\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\nTesting predictions for {country}:\")\n",
    "        \n",
    "        for test_year in test_years:\n",
    "            if test_year not in country_data['year'].values:\n",
    "                continue\n",
    "                \n",
    "            # Remove test year data\n",
    "            test_data = country_data[country_data['year'] == test_year].iloc[0]\n",
    "            train_data = country_data[country_data['year'] != test_year]\n",
    "            \n",
    "            for indicator in indicator_cols:\n",
    "                if pd.notna(test_data[indicator]):\n",
    "                    # Predict using training data\n",
    "                    predicted = predict_indicator_value(\n",
    "                        train_data, indicator, test_year, prediction_method\n",
    "                    )\n",
    "                    \n",
    "                    if predicted is not None and not np.isnan(predicted):\n",
    "                        actual = test_data[indicator]\n",
    "                        error = abs(actual - predicted)\n",
    "                        relative_error = error / abs(actual) if actual != 0 else error\n",
    "                        \n",
    "                        total_predictions += 1\n",
    "                        total_error += relative_error\n",
    "                        \n",
    "                        print(f\"  {indicator} ({test_year}): Actual={actual:.3f}, Predicted={predicted:.3f}, Error={relative_error:.1%}\")\n",
    "    \n",
    "    if total_predictions > 0:\n",
    "        avg_error = total_error / total_predictions\n",
    "        print(f\"\\nOverall prediction accuracy: {(1-avg_error)*100:.1f}% (avg relative error: {avg_error:.1%})\")\n",
    "    else:\n",
    "        print(\"No predictions could be tested.\")\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Specify your file paths\n",
    "    input_file = '/kaggle/input/wgis-governance-1996-2023/Governance wgidataset with variable names.xlsx'  # Update this path\n",
    "    output_file = \"governance_data_filtered_with_predictions.csv\"\n",
    "    \n",
    "    # Define the countries to filter\n",
    "    selected_countries = [\n",
    "        'Argentina', 'Australia', 'Austria', 'Belgium', 'Brazil', 'Bulgaria', \n",
    "        'Canada', 'Chile', 'China', 'Colombia', 'Costa Rica', 'Croatia', \n",
    "        'Cyprus', 'Czech Republic', 'Denmark', 'Estonia', 'Finland', 'France', \n",
    "        'Germany', 'Greece', 'Hungary', 'Iceland', 'India', 'Indonesia', \n",
    "        'Ireland', 'Israel', 'Italy', 'Japan', 'Korea, Rep.', 'Latvia', \n",
    "        'Lithuania', 'Luxembourg', 'Malta', 'Mexico', 'Netherlands', \n",
    "        'New Zealand', 'Norway', 'Peru', 'Poland', 'Portugal', 'Romania', \n",
    "        'Russian Federation', 'Saudi Arabia', 'Slovak Republic', 'Slovenia', \n",
    "        'South Africa', 'Spain', 'Sweden', 'Switzerland', 'Türkiye', \n",
    "        'United Kingdom', 'United States'\n",
    "    ]\n",
    "    \n",
    "    # Define year range\n",
    "    start_year = 1998\n",
    "    end_year = 2018\n",
    "    \n",
    "    # Prediction settings\n",
    "    prediction_method = 'adaptive'  # Options: 'linear', 'polynomial', 'trend', 'adaptive'\n",
    "    target_years = [1999, 2001]  # Years to predict\n",
    "    \n",
    "    try:\n",
    "        # Transform the data\n",
    "        transformed_df = transform_governance_data(input_file)\n",
    "        \n",
    "        # Apply filters\n",
    "        print(f\"\\n\" + \"=\"*60)\n",
    "        print(\"APPLYING FILTERS\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Filtering for {len(selected_countries)} countries from {start_year} to {end_year}\")\n",
    "        \n",
    "        # Filter by countries and year range\n",
    "        filtered_df = transformed_df[\n",
    "            (transformed_df['countryname'].isin(selected_countries)) &\n",
    "            (transformed_df['year'] >= start_year) &\n",
    "            (transformed_df['year'] <= end_year)\n",
    "        ].copy()\n",
    "        \n",
    "        print(f\"Filtered dataset shape: {filtered_df.shape}\")\n",
    "        \n",
    "        # Check which countries from our list are actually in the data\n",
    "        available_countries = set(filtered_df['countryname'].unique())\n",
    "        requested_countries = set(selected_countries)\n",
    "        found_countries = available_countries.intersection(requested_countries)\n",
    "        missing_countries = requested_countries - available_countries\n",
    "        \n",
    "        print(f\"\\nCountries found in dataset: {len(found_countries)}\")\n",
    "        print(f\"Countries not found in dataset: {len(missing_countries)}\")\n",
    "        \n",
    "        if missing_countries:\n",
    "            print(f\"Missing countries: {sorted(list(missing_countries))}\")\n",
    "        \n",
    "        # Analyze prediction quality (optional)\n",
    "        analyze_prediction_quality(filtered_df, list(found_countries), prediction_method=prediction_method)\n",
    "        \n",
    "        # Handle missing data with advanced prediction\n",
    "        print(f\"\\n\" + \"=\"*60)\n",
    "        print(f\"PREDICTING MISSING {target_years} DATA\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Check for missing target year data\n",
    "        countries_needing_prediction = []\n",
    "        \n",
    "        for target_year in target_years:\n",
    "            existing_data = filtered_df[filtered_df['year'] == target_year]\n",
    "            countries_with_data = set(existing_data['countryname'].unique())\n",
    "            countries_without_data = found_countries - countries_with_data\n",
    "            \n",
    "            print(f\"\\n{target_year} data status:\")\n",
    "            print(f\"  Countries with existing data: {len(countries_with_data)}\")\n",
    "            print(f\"  Countries needing prediction: {len(countries_without_data)}\")\n",
    "            \n",
    "            countries_needing_prediction.extend(list(countries_without_data))\n",
    "        \n",
    "        # Remove duplicates\n",
    "        countries_needing_prediction = list(set(countries_needing_prediction))\n",
    "        \n",
    "        if countries_needing_prediction:\n",
    "            print(f\"\\nCountries needing predictions: {len(countries_needing_prediction)}\")\n",
    "            filtered_df = predict_missing_data_advanced(\n",
    "                filtered_df, \n",
    "                countries_needing_prediction, \n",
    "                target_years, \n",
    "                method=prediction_method\n",
    "            )\n",
    "        else:\n",
    "            print(\"All countries have data for target years.\")\n",
    "        \n",
    "        # Save filtered data with predictions\n",
    "        filtered_df.to_csv(output_file, index=False)\n",
    "        print(f\"\\nFiltered data with predictions saved to: {output_file}\")\n",
    "        \n",
    "        # Display sample of the filtered data\n",
    "        display_sample_data(filtered_df)\n",
    "        \n",
    "        # Additional analysis for filtered data\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"FINAL DATA ANALYSIS\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Year range in filtered data\n",
    "        actual_year_range = f\"{filtered_df['year'].min()} - {filtered_df['year'].max()}\"\n",
    "        print(f\"Actual year range in filtered data: {actual_year_range}\")\n",
    "        \n",
    "        # Number of observations per country\n",
    "        country_obs = filtered_df['countryname'].value_counts().sort_index()\n",
    "        print(f\"\\nObservations per country ({start_year}-{end_year}):\")\n",
    "        for country, count in country_obs.items():\n",
    "            expected_years = end_year - start_year + 1\n",
    "            print(f\"  {country}: {count} observations (expected: {expected_years})\")\n",
    "        \n",
    "        # Check for complete records (all 6 indicators)\n",
    "        complete_filtered = filtered_df.dropna()\n",
    "        print(f\"\\nComplete records in filtered data: {len(complete_filtered)} out of {len(filtered_df)}\")\n",
    "        \n",
    "        # Missing data by indicator in filtered dataset\n",
    "        print(f\"\\nMissing data by indicator (after predictions):\")\n",
    "        indicator_cols = [col for col in filtered_df.columns if col not in ['countryname', 'year']]\n",
    "        for col in indicator_cols:\n",
    "            missing_count = filtered_df[col].isna().sum()\n",
    "            missing_pct = (missing_count / len(filtered_df)) * 100\n",
    "            print(f\"  {col}: {missing_count} missing ({missing_pct:.1f}%)\")\n",
    "        \n",
    "        # Summary statistics for filtered data\n",
    "        print(f\"\\nGovernance indicators summary (after predictions):\")\n",
    "        print(filtered_df[indicator_cols].describe().round(3))\n",
    "        \n",
    "        # Save complete records only\n",
    "        complete_output_file = \"governance_data_complete_with_predictions.csv\"\n",
    "        if len(complete_filtered) > 0:\n",
    "            complete_filtered.to_csv(complete_output_file, index=False)\n",
    "            print(f\"\\nComplete records only saved to: {complete_output_file}\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Could not find the file '{input_file}'\")\n",
    "        print(\"Please make sure the file exists in the current directory.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# Additional utility functions for prediction analysis\n",
    "\n",
    "def compare_prediction_methods(df, countries_list, test_year=2000):\n",
    "    \"\"\"\n",
    "    Compare different prediction methods on a test year.\n",
    "    \"\"\"\n",
    "    methods = ['linear', 'polynomial', 'trend', 'adaptive']\n",
    "    indicator_cols = [col for col in df.columns if col not in ['countryname', 'year']]\n",
    "    \n",
    "    results = {method: [] for method in methods}\n",
    "    \n",
    "    for country in countries_list[:10]:  # Test on subset\n",
    "        country_data = df[df['countryname'] == country].copy()\n",
    "        \n",
    "        if test_year not in country_data['year'].values:\n",
    "            continue\n",
    "            \n",
    "        # Get actual values\n",
    "        actual_data = country_data[country_data['year'] == test_year].iloc[0]\n",
    "        train_data = country_data[country_data['year'] != test_year]\n",
    "        \n",
    "        for method in methods:\n",
    "            method_errors = []\n",
    "            for indicator in indicator_cols:\n",
    "                if pd.notna(actual_data[indicator]):\n",
    "                    predicted = predict_indicator_value(train_data, indicator, test_year, method)\n",
    "                    if predicted is not None and not np.isnan(predicted):\n",
    "                        actual = actual_data[indicator]\n",
    "                        error = abs(actual - predicted) / abs(actual) if actual != 0 else abs(predicted)\n",
    "                        method_errors.append(error)\n",
    "            \n",
    "            if method_errors:\n",
    "                results[method].extend(method_errors)\n",
    "    \n",
    "    print(\"\\nPrediction Method Comparison (Average Relative Error):\")\n",
    "    for method, errors in results.items():\n",
    "        if errors:\n",
    "            avg_error = np.mean(errors)\n",
    "            print(f\"  {method.capitalize()}: {avg_error:.1%}\")\n",
    "\n",
    "def export_prediction_summary(df, output_file=\"prediction_summary.csv\"):\n",
    "    \"\"\"\n",
    "    Export a summary of predicted vs actual data for validation.\n",
    "    \"\"\"\n",
    "    # This would be used after running predictions to analyze results\n",
    "    predicted_rows = df[df['year'].isin([1999, 2001])]\n",
    "    if len(predicted_rows) > 0:\n",
    "        predicted_rows.to_csv(output_file, index=False)\n",
    "        print(f\"Prediction summary saved to: {output_file}\")\n",
    "    \n",
    "    return predicted_rows"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7487574,
     "sourceId": 11910248,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 33.842901,
   "end_time": "2025-05-23T16:16:39.112971",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-23T16:16:05.270070",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
